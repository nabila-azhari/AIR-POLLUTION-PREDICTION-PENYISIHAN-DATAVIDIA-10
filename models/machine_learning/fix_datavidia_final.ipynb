{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datavidia ISPU Prediction - Fixed Version\n",
    "\n",
    "Notebook ini memperbaiki error `AttributeError: Can only use .dt accessor with datetimelike values` dan mengatasi masalah **Data Leakage**.\n",
    "\n",
    "### Perubahan Utama:\n",
    "1. **Datetime Fix**: Penambahan konversi `pd.to_datetime` yang lebih aman sebelum pembuatan fitur.\n",
    "2. **Anti-Leakage**: Model hanya melihat data kemarin (t-1) dan sebelumnya untuk memprediksi hari ini.\n",
    "3. **Submission Logic**: Menggunakan merge untuk memastikan urutan ID sesuai dengan `sample_submission.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded: 15257 rows\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "\n",
    "# =========================\n",
    "# 1. KONFIGURASI & LOAD DATA\n",
    "# =========================\n",
    "NA_VALUES = [\"---\", \"--\", \"\", \" \", \"NA\", \"N/A\"]\n",
    "LABEL_MAP = {\"BAIK\": 0, \"SEDANG\": 1, \"TIDAK SEHAT\": 2}\n",
    "INV_LABEL_MAP = {v: k for k, v in LABEL_MAP.items()}\n",
    "\n",
    "def find_file(name):\n",
    "    for path in [Path.cwd()] + list(Path.cwd().parents):\n",
    "        matches = list(path.rglob(name))\n",
    "        if matches: return matches[0]\n",
    "    return None\n",
    "\n",
    "path_main = find_file(\"merged_cuaca_ndvi_ispu.csv\")\n",
    "path_sub = find_file(\"sample_submission.csv\")\n",
    "\n",
    "if path_main is None:\n",
    "    raise FileNotFoundError(\"‚ùå File merged_cuaca_ndvi_ispu.csv tidak ditemukan!\")\n",
    "\n",
    "df = pd.read_csv(path_main, na_values=NA_VALUES)\n",
    "\n",
    "# PREPROCESSING AWAL\n",
    "df[\"tanggal\"] = pd.to_datetime(df[\"tanggal\"])\n",
    "df[\"kategori\"] = df[\"kategori\"].replace({\n",
    "    \"SANGAT TIDAK SEHAT\": \"TIDAK SEHAT\",\n",
    "    \"BERBAHAYA\": \"TIDAK SEHAT\"\n",
    "})\n",
    "df = df.dropna(subset=[\"kategori\"])\n",
    "df = df.sort_values([\"lokasi_clean\", \"tanggal\"]).reset_index(drop=True)\n",
    "df[\"y\"] = df[\"kategori\"].map(LABEL_MAP)\n",
    "\n",
    "print(f\"Data loaded: {len(df)} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî® Building features...\n",
      "Total features: 33\n"
     ]
    }
   ],
   "source": [
    "def create_features(data):\n",
    "    data = data.copy()\n",
    "    \n",
    "    # Pastikan tipe datetime untuk akses .dt\n",
    "    data[\"tanggal\"] = pd.to_datetime(data[\"tanggal\"])\n",
    "    \n",
    "    # Fitur Kalender\n",
    "    data[\"month\"] = data[\"tanggal\"].dt.month\n",
    "    data[\"day_of_week\"] = data[\"tanggal\"].dt.dayofweek\n",
    "    data[\"is_weekend\"] = data[\"day_of_week\"].isin([5, 6]).astype(int)\n",
    "    \n",
    "    # List fitur dasar\n",
    "    POLLUTANTS = [\"pm_sepuluh\", \"sulfur_dioksida\", \"karbon_monoksida\", \"ozon\", \"nitrogen_dioksida\"]\n",
    "    WEATHER = [\n",
    "        \"temperature_2m_mean (¬∞C)\", \"relative_humidity_2m_mean (%)\",\n",
    "        \"precipitation_sum (mm)\", \"wind_speed_10m_mean (km/h)\", \"ndvi\"\n",
    "    ]\n",
    "    COLS_TO_SHIFT = [c for c in POLLUTANTS + WEATHER if c in data.columns]\n",
    "    \n",
    "    for col in COLS_TO_SHIFT:\n",
    "        # Lags: Menggunakan data H-1 s/d H-3 untuk prediksi hari H (Anti-Leakage)\n",
    "        data[f\"{col}_lag_1\"] = data.groupby(\"lokasi_clean\")[col].shift(1)\n",
    "        data[f\"{col}_lag_2\"] = data.groupby(\"lokasi_clean\")[col].shift(2)\n",
    "        \n",
    "        # Rolling Mean 7 hari terakhir (berdasarkan data s/d kemarin)\n",
    "        data[f\"{col}_roll7\"] = (\n",
    "            data.groupby(\"lokasi_clean\")[col]\n",
    "            .transform(lambda x: x.shift(1).rolling(7, min_periods=3).mean())\n",
    "        )\n",
    "        \n",
    "    return data\n",
    "\n",
    "print(\"üî® Building features...\")\n",
    "df_feat = create_features(df)\n",
    "\n",
    "# Hanya gunakan fitur lag/roll dan kalender (BUKAN base features hari H)\n",
    "FEATURES = [c for c in df_feat.columns if \"_lag_\" in c or \"_roll\" in c or c in [\"month\", \"day_of_week\", \"is_weekend\"]]\n",
    "print(f\"Total features: {len(FEATURES)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002641 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5357\n",
      "[LightGBM] [Info] Number of data points in the train set: 14049, number of used features: 33\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score -2.310997\n",
      "[LightGBM] [Info] Start training from score -1.010063\n",
      "[LightGBM] [Info] Start training from score -0.622425\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[341]\tvalid_0's multi_logloss: 0.732343\n",
      "\n",
      "--- VALIDATION REPORT ---\n",
      "Macro F1: 0.4979\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        BAIK       0.55      0.45      0.50       218\n",
      "      SEDANG       0.75      0.79      0.77       849\n",
      " TIDAK SEHAT       0.23      0.22      0.23       141\n",
      "\n",
      "    accuracy                           0.66      1208\n",
      "   macro avg       0.51      0.49      0.50      1208\n",
      "weighted avg       0.65      0.66      0.66      1208\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# 3. TRAINING & VALIDATION\n",
    "# =========================\n",
    "SPLIT_DATE = \"2024-12-31\"\n",
    "train_mask = (df_feat[\"tanggal\" ] < SPLIT_DATE) & (df_feat[\"y\"].notna())\n",
    "valid_mask = (df_feat[\"tanggal\"] >= SPLIT_DATE) & (df_feat[\"y\"].notna())\n",
    "\n",
    "X_train, y_train = df_feat.loc[train_mask, FEATURES], df_feat.loc[train_mask, \"y\"]\n",
    "X_valid, y_valid = df_feat.loc[valid_mask, FEATURES], df_feat.loc[valid_mask, \"y\"]\n",
    "\n",
    "model = lgb.LGBMClassifier(\n",
    "    objective=\"multiclass\",\n",
    "    num_class=3,\n",
    "    n_estimators=1000,\n",
    "    learning_rate=0.03,\n",
    "    class_weight={0: 1.0, 1: 0.8, 2: 4.5}, # Penalti berat jika salah prediksi TIDAK SEHAT\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_valid, y_valid)],\n",
    "    callbacks=[lgb.early_stopping(stopping_rounds=50)]\n",
    ")\n",
    "\n",
    "y_pred = model.predict(X_valid)\n",
    "print(\"\\n--- VALIDATION REPORT ---\")\n",
    "print(f\"Macro F1: {f1_score(y_valid, y_pred, average='macro'):.4f}\")\n",
    "print(classification_report(y_valid, y_pred, target_names=LABEL_MAP.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è ID di sample_submission tidak ditemukan dalam data fitur!\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# 4. GENERATE SUBMISSION\n",
    "# =========================\n",
    "if path_sub:\n",
    "    sub = pd.read_csv(path_sub)\n",
    "    \n",
    "    # Gunakan ID dari sample submission untuk mengambil baris yang sudah ada fiturnya\n",
    "    sub_data = df_feat[df_feat[\"id\"].isin(sub[\"id\"])].copy()\n",
    "    \n",
    "    if len(sub_data) > 0:\n",
    "        # Prediksi\n",
    "        preds = model.predict(sub_data[FEATURES])\n",
    "        sub_data[\"category\"] = [INV_LABEL_MAP[p] for p in preds]\n",
    "        \n",
    "        # Gabungkan kembali agar urutan ID tetap sama dengan sample_submission\n",
    "        final_sub = sub[[\"id\"]].merge(sub_data[[\"id\", \"category\"]], on=\"id\", how=\"left\")\n",
    "        \n",
    "        # Isi nilai kosong (jika ada ID yang tidak masuk ke dataset utama)\n",
    "        final_sub[\"category\"] = final_sub[\"category\"].fillna(\"SEDANG\")\n",
    "        \n",
    "        final_sub.to_csv(\"submission.csv\", index=False)\n",
    "        print(\"‚úÖ submission.csv berhasil dibuat!\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è ID di sample_submission tidak ditemukan dalam data fitur!\")\n",
    "else:\n",
    "    print(\"‚ùå sample_submission.csv tidak ditemukan.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
