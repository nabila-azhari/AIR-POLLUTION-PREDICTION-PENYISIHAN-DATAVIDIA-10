{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "238866be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "\n",
    "NA_VALUES = [\"---\", \"--\", \"\", \" \", \"NA\", \"N/A\"]\n",
    "# =========================\n",
    "# FILE FINDER\n",
    "# =========================\n",
    "def find_file(name, start=Path.cwd()):\n",
    "    for ancestor in [start] + list(start.parents):\n",
    "        matches = list(ancestor.rglob(name))\n",
    "        if matches:\n",
    "            return matches[0]\n",
    "    return None\n",
    "\n",
    "\n",
    "def find_files(file_map):\n",
    "    found = {}\n",
    "    for key, filename in file_map.items():\n",
    "        path = find_file(filename)\n",
    "        if path:\n",
    "            found[key] = path\n",
    "        else:\n",
    "            print(f\"[WARNING] File not found: {filename}\")\n",
    "    return found\n",
    "\n",
    "eda_script_path = find_file(\"script_eda.py\")\n",
    "if eda_script_path is None:\n",
    "    raise FileNotFoundError(\"❌ script_eda.py tidak ditemukan di parent directory\")\n",
    "\n",
    "# tambahkan BASE PROJECT ke sys.path\n",
    "sys.path.append(str(eda_script_path.parent))\n",
    "\n",
    "# sekarang bisa import\n",
    "from script_eda import evaluate_dataset, extract_column_schema,find_internal_duplicate_columns,extract_single_schema,cek_value_data_column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "9d621f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = find_file(\"merged_cuaca_ndvi_ispu.csv\")\n",
    "\n",
    "if path is None:\n",
    "    raise FileNotFoundError(\"❌ File merged tidak ditemukan\")\n",
    "\n",
    "df = pd.read_csv(path, na_values=NA_VALUES)\n",
    "\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "69b57325",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "REQUIRED_COLS = [\"tanggal\", \"lokasi_clean\", \"kategori\"]\n",
    "missing = [c for c in REQUIRED_COLS if c not in df.columns]\n",
    "assert len(missing) == 0, f\"Missing columns: {missing}\"\n",
    "df[\"tanggal\"] = pd.to_datetime(df[\"tanggal\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "1e7dc4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=[\"kategori\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "99968aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"kategori\"] = df[\"kategori\"].replace({\n",
    "    \"SANGAT TIDAK SEHAT\": \"TIDAK SEHAT\",\n",
    "    \"BERBAHAYA\": \"TIDAK SEHAT\"\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "eecb7b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values([\"lokasi_clean\", \"tanggal\"]).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "e164bf10",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"prev_tanggal\"] = df.groupby(\"lokasi_clean\")[\"tanggal\"].shift(1)\n",
    "df[\"delta_days\"] = (df[\"tanggal\"] - df[\"prev_tanggal\"]).dt.days\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "5778d7c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    15252.000000\n",
       "mean         1.744820\n",
       "std          6.412906\n",
       "min          1.000000\n",
       "25%          1.000000\n",
       "50%          1.000000\n",
       "75%          1.000000\n",
       "max        339.000000\n",
       "Name: delta_days, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df[\"delta_days\"].describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "ebb31503",
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL_MAP = {\n",
    "    \"BAIK\": 0,\n",
    "    \"SEDANG\": 1,\n",
    "    \"TIDAK SEHAT\": 2\n",
    "}\n",
    "INV_LABEL_MAP = {v: k for k, v in LABEL_MAP.items()}\n",
    "\n",
    "df[\"y\"] = df[\"kategori\"].map(LABEL_MAP)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "7cf18d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LABEL_MAP_PARAM = {\n",
    "#     \"PM10\": 0,\n",
    "#     \"SO2\": 1,\n",
    "#     \"CO\": 2,\n",
    "#     \"O3\": 3,\n",
    "#     \"NO2\": 4,\n",
    "# }\n",
    "# INV_LABEL_MAP_PARAM = {v: k for k, v in LABEL_MAP_PARAM.items()}\n",
    "\n",
    "# df[\"y_param\"] = df[\"parameter_pencemar_kritis\"].map(LABEL_MAP_PARAM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "fd9ad853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[[\"parameter_pencemar_kritis\", \"y_param\"]].head()\n",
    "# df[\"y_param\"].value_counts(dropna=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "e342ddac",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_FEATURES = [\n",
    "    \"pm_sepuluh\", \"sulfur_dioksida\", \"karbon_monoksida\", \"ozon\", \"nitrogen_dioksida\",\n",
    "    \"temperature_2m_mean (°C)\",\n",
    "    \"relative_humidity_2m_mean (%)\",\n",
    "    \"precipitation_sum (mm)\",\n",
    "    \"wind_speed_10m_mean (km/h)\",\n",
    "    \"cloud_cover_mean (%)\",\n",
    "    \"ndvi\",\n",
    "]\n",
    "\n",
    "META_FEATURES = [\"delta_days\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "b39a675e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tanggal</th>\n",
       "      <th>periode_data</th>\n",
       "      <th>stasiun</th>\n",
       "      <th>pm_sepuluh</th>\n",
       "      <th>sulfur_dioksida</th>\n",
       "      <th>karbon_monoksida</th>\n",
       "      <th>ozon</th>\n",
       "      <th>nitrogen_dioksida</th>\n",
       "      <th>max</th>\n",
       "      <th>parameter_pencemar_kritis</th>\n",
       "      <th>...</th>\n",
       "      <th>wind_gusts_10m_min (km/h)</th>\n",
       "      <th>wind_speed_10m_min (km/h)</th>\n",
       "      <th>surface_pressure_max (hPa)</th>\n",
       "      <th>surface_pressure_min (hPa)</th>\n",
       "      <th>lokasi</th>\n",
       "      <th>lokasi_clean</th>\n",
       "      <th>ndvi</th>\n",
       "      <th>prev_tanggal</th>\n",
       "      <th>delta_days</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>201001</td>\n",
       "      <td>DKI1 (Bunderan HI)</td>\n",
       "      <td>60.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>CO</td>\n",
       "      <td>...</td>\n",
       "      <td>11.9</td>\n",
       "      <td>6.9</td>\n",
       "      <td>1009.3</td>\n",
       "      <td>1005.1</td>\n",
       "      <td>dki1_bundaranhi</td>\n",
       "      <td>DKI1</td>\n",
       "      <td>0.2023</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-01-02</td>\n",
       "      <td>201001</td>\n",
       "      <td>DKI1 (Bunderan HI)</td>\n",
       "      <td>32.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>O3</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1009.9</td>\n",
       "      <td>1006.0</td>\n",
       "      <td>dki1_bundaranhi</td>\n",
       "      <td>DKI1</td>\n",
       "      <td>0.2023</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-01-03</td>\n",
       "      <td>201001</td>\n",
       "      <td>DKI1 (Bunderan HI)</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>PM10</td>\n",
       "      <td>...</td>\n",
       "      <td>11.9</td>\n",
       "      <td>6.5</td>\n",
       "      <td>1010.5</td>\n",
       "      <td>1006.5</td>\n",
       "      <td>dki1_bundaranhi</td>\n",
       "      <td>DKI1</td>\n",
       "      <td>0.2023</td>\n",
       "      <td>2010-01-02</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>201001</td>\n",
       "      <td>DKI1 (Bunderan HI)</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>PM10</td>\n",
       "      <td>...</td>\n",
       "      <td>14.4</td>\n",
       "      <td>9.6</td>\n",
       "      <td>1009.1</td>\n",
       "      <td>1005.1</td>\n",
       "      <td>dki1_bundaranhi</td>\n",
       "      <td>DKI1</td>\n",
       "      <td>0.2023</td>\n",
       "      <td>2010-01-03</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-01-05</td>\n",
       "      <td>201001</td>\n",
       "      <td>DKI1 (Bunderan HI)</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>PM10</td>\n",
       "      <td>...</td>\n",
       "      <td>10.4</td>\n",
       "      <td>7.8</td>\n",
       "      <td>1009.1</td>\n",
       "      <td>1006.0</td>\n",
       "      <td>dki1_bundaranhi</td>\n",
       "      <td>DKI1</td>\n",
       "      <td>0.2023</td>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     tanggal  periode_data             stasiun  pm_sepuluh  sulfur_dioksida  \\\n",
       "0 2010-01-01        201001  DKI1 (Bunderan HI)        60.0              4.0   \n",
       "1 2010-01-02        201001  DKI1 (Bunderan HI)        32.0              2.0   \n",
       "2 2010-01-03        201001  DKI1 (Bunderan HI)        27.0              2.0   \n",
       "3 2010-01-04        201001  DKI1 (Bunderan HI)        22.0              2.0   \n",
       "4 2010-01-05        201001  DKI1 (Bunderan HI)        25.0              2.0   \n",
       "\n",
       "   karbon_monoksida  ozon  nitrogen_dioksida   max parameter_pencemar_kritis  \\\n",
       "0              73.0  27.0               14.0  73.0                        CO   \n",
       "1              16.0  33.0                9.0  33.0                        O3   \n",
       "2              19.0  20.0                9.0  27.0                      PM10   \n",
       "3              16.0  15.0                6.0  22.0                      PM10   \n",
       "4              17.0  15.0                8.0  25.0                      PM10   \n",
       "\n",
       "   ... wind_gusts_10m_min (km/h) wind_speed_10m_min (km/h)  \\\n",
       "0  ...                      11.9                       6.9   \n",
       "1  ...                       9.0                       4.4   \n",
       "2  ...                      11.9                       6.5   \n",
       "3  ...                      14.4                       9.6   \n",
       "4  ...                      10.4                       7.8   \n",
       "\n",
       "  surface_pressure_max (hPa)  surface_pressure_min (hPa)           lokasi  \\\n",
       "0                     1009.3                      1005.1  dki1_bundaranhi   \n",
       "1                     1009.9                      1006.0  dki1_bundaranhi   \n",
       "2                     1010.5                      1006.5  dki1_bundaranhi   \n",
       "3                     1009.1                      1005.1  dki1_bundaranhi   \n",
       "4                     1009.1                      1006.0  dki1_bundaranhi   \n",
       "\n",
       "   lokasi_clean    ndvi  prev_tanggal  delta_days  y  \n",
       "0          DKI1  0.2023           NaT         NaN  1  \n",
       "1          DKI1  0.2023    2010-01-01         1.0  0  \n",
       "2          DKI1  0.2023    2010-01-02         1.0  0  \n",
       "3          DKI1  0.2023    2010-01-03         1.0  0  \n",
       "4          DKI1  0.2023    2010-01-04         1.0  0  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "0942d02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "LAG_FEATURES = []\n",
    "\n",
    "for col in BASE_FEATURES:\n",
    "    lag_col = f\"{col}_lag_1_safe\"\n",
    "    df[lag_col] = np.where(\n",
    "        df[\"delta_days\"] <= 2,\n",
    "        df.groupby(\"lokasi_clean\")[col].shift(1),\n",
    "        np.nan\n",
    "    )\n",
    "    LAG_FEATURES.append(lag_col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "05713c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROLL7_FEATURES = []\n",
    "\n",
    "for col in BASE_FEATURES:\n",
    "    roll_col = f\"{col}_roll7\"\n",
    "    df[roll_col] = (\n",
    "        df.groupby(\"lokasi_clean\")[col]\n",
    "          .shift(1)\n",
    "          .rolling(7, min_periods=3)\n",
    "          .mean()\n",
    "    )\n",
    "    ROLL7_FEATURES.append(roll_col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad32828",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le_loc = LabelEncoder()\n",
    "df[\"loc_id\"] = le_loc.fit_transform(df[\"lokasi_clean\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c87d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LEN = 14\n",
    "\n",
    "FEATURES = (\n",
    "    BASE_FEATURES\n",
    "    + META_FEATURES\n",
    "    + ROLL7_FEATURES\n",
    "    + [\"loc_id\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "10f8ea30",
   "metadata": {},
   "outputs": [],
   "source": [
    "SPLIT_DATE = \"2024-12-31\"\n",
    "\n",
    "train_df = df[df[\"tanggal\"] < SPLIT_DATE]\n",
    "valid_df = df[df[\"tanggal\"] >= SPLIT_DATE]\n",
    "\n",
    "X_train = train_df[FEATURES]\n",
    "y_train = train_df[\"y\"]\n",
    "\n",
    "X_valid = valid_df[FEATURES]\n",
    "y_valid = valid_df[\"y\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ffafdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_sequences(df, seq_len, features, target=\"y\"):\n",
    "    X, y = [], []\n",
    "\n",
    "    for lokasi, g in df.groupby(\"lokasi_clean\"):\n",
    "        g = g.sort_values(\"tanggal\")\n",
    "\n",
    "        vals = g[features].values\n",
    "        labels = g[target].values\n",
    "\n",
    "        for i in range(seq_len, len(g)):\n",
    "            X.append(vals[i-seq_len:i])\n",
    "            y.append(labels[i])\n",
    "\n",
    "    return np.array(X), np.array(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1358310a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = build_sequences(train_df, SEQ_LEN, FEATURES)\n",
    "X_valid, y_valid = build_sequences(valid_df, SEQ_LEN, FEATURES)\n",
    "\n",
    "print(\"Train:\", X_train.shape)\n",
    "print(\"Valid:\", X_valid.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d37e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "n_features = X_train.shape[-1]\n",
    "\n",
    "X_train_2d = X_train.reshape(-1, n_features)\n",
    "X_valid_2d = X_valid.reshape(-1, n_features)\n",
    "\n",
    "scaler.fit(X_train_2d)\n",
    "\n",
    "X_train = scaler.transform(X_train_2d).reshape(X_train.shape)\n",
    "X_valid = scaler.transform(X_valid_2d).reshape(X_valid.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858147a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model\n",
    "\n",
    "SEQ_LEN = X_train.shape[1]\n",
    "N_FEATURES = X_train.shape[2]\n",
    "\n",
    "inputs = layers.Input(shape=(SEQ_LEN, N_FEATURES))\n",
    "\n",
    "x = layers.Masking(mask_value=np.nan)(inputs)\n",
    "\n",
    "# BiLSTM 1\n",
    "x = layers.Bidirectional(\n",
    "    layers.LSTM(\n",
    "        64,\n",
    "        return_sequences=True,\n",
    "        dropout=0.2,\n",
    "        recurrent_dropout=0.2\n",
    "    )\n",
    ")(x)\n",
    "\n",
    "x = layers.LayerNormalization()(x)\n",
    "\n",
    "# BiLSTM 2 (lebih kecil)\n",
    "x = layers.Bidirectional(\n",
    "    layers.LSTM(\n",
    "        32,\n",
    "        return_sequences=True,\n",
    "        dropout=0.2,\n",
    "        recurrent_dropout=0.2\n",
    "    )\n",
    ")(x)\n",
    "\n",
    "# ===== Attention sederhana =====\n",
    "score = layers.Dense(1, activation=\"tanh\")(x)\n",
    "weights = layers.Softmax(axis=1)(score)\n",
    "context = tf.reduce_sum(weights * x, axis=1)\n",
    "\n",
    "# Dense head\n",
    "x = layers.Dense(64, activation=\"relu\")(context)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "\n",
    "outputs = layers.Dense(3, activation=\"softmax\")(x)\n",
    "\n",
    "model = Model(inputs, outputs)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96963ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "\n",
    "classes = np.unique(y_train)\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight=\"balanced\",\n",
    "    classes=classes,\n",
    "    y=y_train\n",
    ")\n",
    "\n",
    "class_weight_dict = dict(zip(classes, class_weights))\n",
    "print(class_weight_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75224d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        patience=8,\n",
    "        restore_best_weights=True,\n",
    "        monitor=\"val_loss\"\n",
    "    ),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        factor=0.5,\n",
    "        patience=4,\n",
    "        min_lr=1e-5\n",
    "    )\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12e4477",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    epochs=60,\n",
    "    batch_size=64,\n",
    "    class_weight=class_weight_dict,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5343fa76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, classification_report\n",
    "import numpy as np\n",
    "\n",
    "y_pred = np.argmax(model.predict(X_valid), axis=1)\n",
    "\n",
    "print(\"Macro F1:\", f1_score(y_valid, y_pred, average=\"macro\"))\n",
    "print(classification_report(y_valid, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
