{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03ce7eb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_9136\\870952051.py:39: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.groupby(\"lokasi_clean\", group_keys=False).apply(reindex_daily)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_9136\\870952051.py:98: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.groupby(\"lokasi_clean\", group_keys=False).apply(create_features)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold: [0.49487179487179483, 0.49487179487179483, 0.23846153846153847]\n",
      "Valid Macro-F1: 0.845020814656564\n",
      "✅ submission_final.csv siap upload\n"
     ]
    }
   ],
   "source": [
    "# =========================================================\n",
    "# 0. IMPORT\n",
    "# =========================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# =========================================================\n",
    "# 1. LOAD & BASIC CLEANING\n",
    "# =========================================================\n",
    "PATH = Path(\"merged_libur_cuaca_ispu_ndvi.csv\")\n",
    "df = pd.read_csv(PATH, sep=\";\")\n",
    "\n",
    "df[\"tanggal\"] = pd.to_datetime(df[\"tanggal\"], dayfirst=True)\n",
    "df = df.sort_values([\"lokasi_clean\", \"tanggal\"]).reset_index(drop=True)\n",
    "\n",
    "DROP_COLS = [\"max\", \"parameter_pencemar_kritis\", \"time\", \"id\", \"stasiun\"]\n",
    "df = df.drop(columns=DROP_COLS, errors=\"ignore\")\n",
    "\n",
    "LABEL_MAP = {\"BAIK\": 0, \"SEDANG\": 1, \"TIDAK SEHAT\": 2}\n",
    "df = df[df[\"kategori\"].notna()].copy()\n",
    "df[\"target\"] = df[\"kategori\"].map(LABEL_MAP).astype(int)\n",
    "\n",
    "# =========================================================\n",
    "# 2. REINDEX DAILY PER LOKASI\n",
    "# =========================================================\n",
    "def reindex_daily(g):\n",
    "    idx = pd.date_range(g[\"tanggal\"].min(), g[\"tanggal\"].max(), freq=\"D\")\n",
    "    g = g.set_index(\"tanggal\").reindex(idx)\n",
    "    g[\"lokasi_clean\"] = g[\"lokasi_clean\"].iloc[0]\n",
    "    return g.reset_index().rename(columns={\"index\": \"tanggal\"})\n",
    "\n",
    "df = df.groupby(\"lokasi_clean\", group_keys=False).apply(reindex_daily)\n",
    "\n",
    "# =========================================================\n",
    "# 3. PM2.5 IMPUTATION + FLAG\n",
    "# =========================================================\n",
    "df[\"pm25_missing\"] = df[\"pm_duakomalima\"].isna().astype(int)\n",
    "\n",
    "median_pm25 = (\n",
    "    df[df[\"tanggal\"] >= \"2021-01-01\"]\n",
    "    .groupby(\"lokasi_clean\")[\"pm_duakomalima\"]\n",
    "    .median()\n",
    ")\n",
    "\n",
    "df[\"pm_duakomalima\"] = df[\"pm_duakomalima\"].fillna(\n",
    "    df[\"lokasi_clean\"].map(median_pm25)\n",
    ")\n",
    "\n",
    "df = df[df[\"target\"].notna()].copy()\n",
    "\n",
    "# =========================================================\n",
    "# 4. TIME FEATURES\n",
    "# =========================================================\n",
    "df[\"month\"] = df[\"tanggal\"].dt.month\n",
    "df[\"dayofyear\"] = df[\"tanggal\"].dt.dayofyear\n",
    "df[\"dayofweek\"] = df[\"tanggal\"].dt.dayofweek\n",
    "\n",
    "df[\"month_sin\"] = np.sin(2*np.pi*df[\"month\"]/12)\n",
    "df[\"month_cos\"] = np.cos(2*np.pi*df[\"month\"]/12)\n",
    "df[\"doy_sin\"] = np.sin(2*np.pi*df[\"dayofyear\"]/365)\n",
    "df[\"doy_cos\"] = np.cos(2*np.pi*df[\"dayofyear\"]/365)\n",
    "\n",
    "# =========================================================\n",
    "# 5. LAG + ROLLING + TREND FEATURES\n",
    "# =========================================================\n",
    "POLLUTANT_COLS = [\n",
    "    \"pm_sepuluh\",\"pm_duakomalima\",\"ozon\",\n",
    "    \"nitrogen_dioksida\",\"sulfur_dioksida\",\"karbon_monoksida\",\n",
    "]\n",
    "\n",
    "LAGS = [1,2,3,7]\n",
    "ROLL = [3,7,14]\n",
    "\n",
    "def create_features(g):\n",
    "    g = g.sort_values(\"tanggal\")\n",
    "\n",
    "    for col in POLLUTANT_COLS:\n",
    "        for l in LAGS:\n",
    "            g[f\"{col}_lag{l}\"] = g[col].shift(l)\n",
    "\n",
    "        for w in ROLL:\n",
    "            g[f\"{col}_rmean{w}\"] = g[col].shift(1).rolling(w).mean()\n",
    "            g[f\"{col}_rstd{w}\"]  = g[col].shift(1).rolling(w).std()\n",
    "\n",
    "        # trend / delta\n",
    "        g[f\"{col}_diff1\"] = g[col].diff(1)\n",
    "        g[f\"{col}_diff7\"] = g[col].diff(7)\n",
    "\n",
    "    return g\n",
    "\n",
    "df = df.groupby(\"lokasi_clean\", group_keys=False).apply(create_features)\n",
    "\n",
    "# =========================================================\n",
    "# 6. DROP NA FROM LAGGING\n",
    "# =========================================================\n",
    "df_model = df.dropna().reset_index(drop=True)\n",
    "\n",
    "# =========================================================\n",
    "# 7. ENCODE LOKASI\n",
    "# =========================================================\n",
    "le_loc = LabelEncoder()\n",
    "df_model[\"lokasi_enc\"] = le_loc.fit_transform(df_model[\"lokasi_clean\"])\n",
    "\n",
    "# =========================================================\n",
    "# 8. TIME-BASED SPLIT (NO LEAKAGE)\n",
    "# =========================================================\n",
    "split_date = df_model[\"tanggal\"].quantile(0.8)\n",
    "\n",
    "train = df_model[df_model[\"tanggal\"] <= split_date]\n",
    "valid = df_model[df_model[\"tanggal\"] > split_date]\n",
    "\n",
    "# =========================================================\n",
    "# 9. TRAIN ISPU MULTICLASS MODEL\n",
    "# =========================================================\n",
    "FEATURES = (\n",
    "    [c for c in df_model.columns if any(x in c for x in [\"lag\",\"rmean\",\"rstd\",\"diff\"])]\n",
    "    + [\"month_sin\",\"month_cos\",\"doy_sin\",\"doy_cos\",\"lokasi_enc\"]\n",
    ")\n",
    "\n",
    "X_train, y_train = train[FEATURES], train[\"target\"]\n",
    "X_valid, y_valid = valid[FEATURES], valid[\"target\"]\n",
    "\n",
    "train_data = lgb.Dataset(X_train, label=y_train)\n",
    "valid_data = lgb.Dataset(X_valid, label=y_valid)\n",
    "\n",
    "params = {\n",
    "    \"objective\": \"multiclass\",\n",
    "    \"num_class\": 3,\n",
    "    \"metric\": \"multi_logloss\",\n",
    "    \"learning_rate\": 0.03,\n",
    "    \"num_leaves\": 63,\n",
    "    \"min_data_in_leaf\": 40,\n",
    "    \"feature_fraction\": 0.8,\n",
    "    \"bagging_fraction\": 0.8,\n",
    "    \"bagging_freq\": 5,\n",
    "    \"class_weight\": \"balanced\",\n",
    "    \"seed\": SEED,\n",
    "    \"verbosity\": -1,\n",
    "}\n",
    "\n",
    "model = lgb.train(\n",
    "    params,\n",
    "    train_data,\n",
    "    valid_sets=[valid_data],\n",
    "    num_boost_round=2000,\n",
    "    callbacks=[lgb.early_stopping(200, verbose=False)]\n",
    ")\n",
    "\n",
    "# =========================================================\n",
    "# 10. THRESHOLD TUNING (VALIDATION ONLY)\n",
    "# =========================================================\n",
    "probs = model.predict(X_valid)\n",
    "\n",
    "best_t = [0.33,0.33,0.33]\n",
    "\n",
    "for c in range(3):\n",
    "    best_f1 = 0\n",
    "    for t in np.linspace(0.2,0.7,40):\n",
    "        pred = probs.argmax(1)\n",
    "        pred[probs[:,c] > t] = c\n",
    "        f1 = f1_score(y_valid, pred, average=\"macro\")\n",
    "        if f1 > best_f1:\n",
    "            best_f1, best_t[c] = f1, t\n",
    "\n",
    "print(\"Best threshold:\", best_t)\n",
    "print(\"Valid Macro-F1:\", best_f1)\n",
    "\n",
    "# =========================================================\n",
    "# 11. INFERENCE → SUBMISSION\n",
    "# =========================================================\n",
    "sub = pd.read_csv(\"sample_submission.csv\")\n",
    "\n",
    "sub[\"tanggal\"] = pd.to_datetime(sub[\"id\"].str.split(\"_\").str[0])\n",
    "sub[\"lokasi_clean\"] = sub[\"id\"].str.split(\"_\").str[1]\n",
    "sub[\"lokasi_enc\"] = le_loc.transform(sub[\"lokasi_clean\"])\n",
    "\n",
    "# ambil history terakhir tiap lokasi\n",
    "history = (\n",
    "    df_model.sort_values(\"tanggal\")\n",
    "    .groupby(\"lokasi_clean\")\n",
    "    .tail(14)\n",
    ")\n",
    "\n",
    "rows = []\n",
    "\n",
    "for _, r in sub.iterrows():\n",
    "\n",
    "    loc_hist = history[history[\"lokasi_clean\"] == r[\"lokasi_clean\"]].copy()\n",
    "\n",
    "    feat = loc_hist.iloc[-1:][FEATURES].copy()\n",
    "    feat[\"lokasi_enc\"] = r[\"lokasi_enc\"]\n",
    "\n",
    "    prob = model.predict(feat)\n",
    "    pred = prob.argmax(1)\n",
    "\n",
    "    for c,t in enumerate(best_t):\n",
    "        pred[prob[:,c] > t] = c\n",
    "\n",
    "    rows.append(int(pred[0]))\n",
    "\n",
    "INV_LABEL = {0:\"BAIK\",1:\"SEDANG\",2:\"TIDAK SEHAT\"}\n",
    "\n",
    "sub[\"kategori\"] = [INV_LABEL[i] for i in rows]\n",
    "sub[[\"id\",\"kategori\"]].to_csv(\"submission_final.csv\", index=False)\n",
    "\n",
    "print(\"✅ submission_final.csv siap upload\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
