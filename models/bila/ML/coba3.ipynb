{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ebc3927d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_10800\\1664089488.py:31: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.groupby(\"lokasi_clean\", group_keys=False).apply(reindex_daily)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_10800\\1664089488.py:102: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.groupby(\"lokasi_clean\", group_keys=False).apply(create_temporal_features)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_10800\\1664089488.py:106: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_isnan\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_10800\\1664089488.py:106: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_isnan\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_10800\\1664089488.py:106: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_isnan\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_10800\\1664089488.py:106: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_isnan\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_10800\\1664089488.py:106: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_isnan\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_10800\\1664089488.py:106: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_isnan\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_10800\\1664089488.py:106: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_isnan\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_10800\\1664089488.py:106: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_isnan\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_10800\\1664089488.py:106: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_isnan\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_10800\\1664089488.py:106: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_isnan\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_10800\\1664089488.py:106: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_isnan\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_10800\\1664089488.py:106: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_isnan\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_10800\\1664089488.py:106: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_isnan\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_10800\\1664089488.py:106: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_isnan\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_10800\\1664089488.py:106: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_isnan\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_10800\\1664089488.py:106: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_isnan\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_10800\\1664089488.py:106: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_isnan\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_10800\\1664089488.py:106: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_isnan\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_10800\\1664089488.py:106: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_isnan\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_10800\\1664089488.py:106: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_isnan\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_10800\\1664089488.py:106: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_isnan\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_10800\\1664089488.py:106: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_isnan\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_10800\\1664089488.py:106: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_isnan\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_10800\\1664089488.py:106: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_isnan\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_10800\\1664089488.py:106: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_isnan\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_10800\\1664089488.py:106: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_isnan\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_10800\\1664089488.py:106: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_isnan\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_10800\\1664089488.py:106: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_isnan\"] = df[col].isna().astype(int)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "PATH = Path(\"merged_libur_cuaca_ispu_ndvi.csv\")\n",
    "\n",
    "df = pd.read_csv(PATH, sep=\";\")\n",
    "# parse tanggal\n",
    "df[\"tanggal\"] = pd.to_datetime(df[\"tanggal\"], dayfirst=True)\n",
    "\n",
    "# sort\n",
    "df = df.sort_values([\"lokasi_clean\", \"tanggal\"]).reset_index(drop=True)\n",
    "\n",
    "# drop kolom\n",
    "DROP_COLS = [\"max\", \"parameter_pencemar_kritis\", \"time\", \"id\", \"stasiun\"]\n",
    "df = df.drop(columns=DROP_COLS, errors=\"ignore\")\n",
    "\n",
    "# label mapping\n",
    "LABEL_MAP = {\"BAIK\": 0, \"SEDANG\": 1, \"TIDAK SEHAT\": 2}\n",
    "df = df[df[\"kategori\"].notna()].copy()\n",
    "df[\"target\"] = df[\"kategori\"].map(LABEL_MAP).astype(int)\n",
    "\n",
    "\n",
    "# REINDEX \n",
    "def reindex_daily(g):\n",
    "    idx = pd.date_range(g[\"tanggal\"].min(), g[\"tanggal\"].max(), freq=\"D\")\n",
    "    g = g.set_index(\"tanggal\").reindex(idx)\n",
    "    g[\"lokasi_clean\"] = g[\"lokasi_clean\"].iloc[0]\n",
    "    return g.reset_index().rename(columns={\"index\": \"tanggal\"})\n",
    "\n",
    "df = df.groupby(\"lokasi_clean\", group_keys=False).apply(reindex_daily)\n",
    "\n",
    "\n",
    "# PM2.5 HANDLING\n",
    "df[\"pm25_missing\"] = df[\"pm_duakomalima\"].isna().astype(int)\n",
    "\n",
    "median_pm25 = (\n",
    "    df[df[\"tanggal\"] >= \"2021-01-01\"]\n",
    "    .groupby(\"lokasi_clean\")[\"pm_duakomalima\"]\n",
    "    .median()\n",
    ")\n",
    "\n",
    "df[\"pm_duakomalima\"] = df[\"pm_duakomalima\"].fillna(\n",
    "    df[\"lokasi_clean\"].map(median_pm25)\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# TIME FEATURES \n",
    "df[\"month\"] = df[\"tanggal\"].dt.month\n",
    "df[\"dayofyear\"] = df[\"tanggal\"].dt.dayofyear\n",
    "df[\"dayofweek\"] = df[\"tanggal\"].dt.dayofweek\n",
    "\n",
    "df[\"month_sin\"] = np.sin(2*np.pi*df[\"month\"]/12)\n",
    "df[\"month_cos\"] = np.cos(2*np.pi*df[\"month\"]/12)\n",
    "\n",
    "df[\"doy_sin\"] = np.sin(2*np.pi*df[\"dayofyear\"]/365)\n",
    "df[\"doy_cos\"] = np.cos(2*np.pi*df[\"dayofyear\"]/365)\n",
    "\n",
    "df[\"dow_sin\"] = np.sin(2*np.pi*df[\"dayofweek\"]/7)\n",
    "df[\"dow_cos\"] = np.cos(2*np.pi*df[\"dayofweek\"]/7)\n",
    "\n",
    "# fitur lag dan rolling\n",
    "\n",
    "POLLUTANT_COLS = [\n",
    "    \"pm_sepuluh\",\n",
    "    \"pm_duakomalima\",\n",
    "    \"ozon\",\n",
    "    \"nitrogen_dioksida\",\n",
    "    \"sulfur_dioksida\",\n",
    "    \"karbon_monoksida\",\n",
    "]\n",
    "\n",
    "WEATHER_COLS = [\n",
    "    \"temperature_2m_mean (°C)\",\n",
    "    \"relative_humidity_2m_mean (%)\",\n",
    "    \"wind_speed_10m_mean (km/h)\",\n",
    "    \"precipitation_sum (mm)\",\n",
    "    \"cloud_cover_mean (%)\",\n",
    "    \"surface_pressure_mean (hPa)\",\n",
    "]\n",
    "\n",
    "LAG_FEATURES = POLLUTANT_COLS + WEATHER_COLS\n",
    "\n",
    "LAGS = [1, 2, 3]\n",
    "ROLL_WINDOWS = [3, 7]\n",
    "def create_temporal_features(g):\n",
    "    g = g.sort_values(\"tanggal\")\n",
    "    for col in LAG_FEATURES:\n",
    "        for lag in LAGS:\n",
    "            g[f\"{col}_lag_{lag}\"] = g[col].shift(lag)\n",
    "\n",
    "\n",
    "    for col in POLLUTANT_COLS:\n",
    "        for w in ROLL_WINDOWS:\n",
    "            g[f\"{col}_roll_mean_{w}\"] = g[col].shift(1).rolling(w).mean()\n",
    "            g[f\"{col}_roll_std_{w}\"]  = g[col].shift(1).rolling(w).std()\n",
    "\n",
    "    return g\n",
    "\n",
    "df = df.groupby(\"lokasi_clean\", group_keys=False).apply(create_temporal_features)\n",
    "lag_cols = [c for c in df.columns if \"lag_\" in c or \"roll_\" in c]\n",
    "\n",
    "for col in lag_cols:\n",
    "    df[f\"{col}_isnan\"] = df[col].isna().astype(int)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7ff870a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_10800\\934582758.py:10: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_model = df_model.groupby(\"lokasi_clean\", group_keys=False).apply(make_target_lag)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_10800\\934582758.py:26: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  train_df = train_df.groupby(\"lokasi_clean\", group_keys=False).apply(make_lag_features)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_10800\\934582758.py:27: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  valid_df = valid_df.groupby(\"lokasi_clean\", group_keys=False).apply(make_lag_features)\n"
     ]
    }
   ],
   "source": [
    "df_model = df.dropna(subset=[\"target\"]).reset_index(drop=True)\n",
    "\n",
    "def make_target_lag(g):\n",
    "    g = g.sort_values(\"tanggal\")\n",
    "    g[\"target_lag1\"] = g[\"target\"].shift(1)\n",
    "    g[\"target_lag2\"] = g[\"target\"].shift(2)\n",
    "    g[\"target_roll7\"] = g[\"target\"].shift(1).rolling(7).mean()\n",
    "    return g\n",
    "\n",
    "df_model = df_model.groupby(\"lokasi_clean\", group_keys=False).apply(make_target_lag)\n",
    "\n",
    "\n",
    "SPLIT_DATE = \"2024-01-01\"\n",
    "\n",
    "train_df = df_model[df_model[\"tanggal\"] < SPLIT_DATE].copy()\n",
    "valid_df = df_model[df_model[\"tanggal\"] >= SPLIT_DATE].copy()\n",
    "\n",
    "def make_lag_features(g):\n",
    "    g = g.sort_values(\"tanggal\")\n",
    "    for col in POLLUTANT_COLS:\n",
    "        g[f\"{col}_lag1\"] = g[col].shift(1)\n",
    "        g[f\"{col}_lag2\"] = g[col].shift(2)\n",
    "        g[f\"{col}_lag3\"] = g[col].shift(3)\n",
    "    return g\n",
    "\n",
    "train_df = train_df.groupby(\"lokasi_clean\", group_keys=False).apply(make_lag_features)\n",
    "valid_df = valid_df.groupby(\"lokasi_clean\", group_keys=False).apply(make_lag_features)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4abfdf56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le_loc = LabelEncoder()\n",
    "\n",
    "train_df[\"lokasi_enc\"] = le_loc.fit_transform(train_df[\"lokasi_clean\"])\n",
    "valid_df[\"lokasi_enc\"] = le_loc.transform(valid_df[\"lokasi_clean\"])\n",
    "\n",
    "# >>> TAMBAHAN WAJIB\n",
    "df_model[\"lokasi_enc\"] = le_loc.transform(df_model[\"lokasi_clean\"])\n",
    "\n",
    "FEATURES_F = (\n",
    "    [f\"{c}_lag1\" for c in POLLUTANT_COLS] +\n",
    "    [f\"{c}_lag2\" for c in POLLUTANT_COLS] +\n",
    "    [f\"{c}_lag3\" for c in POLLUTANT_COLS] +\n",
    "    [\"month\", \"dayofyear\", \"dayofweek\", \"lokasi_enc\"]\n",
    ")\n",
    "\n",
    "pollutant_models = {}\n",
    "\n",
    "for col in POLLUTANT_COLS:\n",
    "    X = train_df[FEATURES_F]\n",
    "    y = train_df[col]\n",
    "\n",
    "    dtrain = lgb.Dataset(X, label=y)\n",
    "\n",
    "    model = lgb.train(\n",
    "        {\n",
    "            \"objective\": \"regression\",\n",
    "            \"metric\": \"l2\",\n",
    "            \"learning_rate\": 0.05,\n",
    "            \"num_leaves\": 64,\n",
    "            \"verbosity\": -1,\n",
    "            \"seed\": 42,\n",
    "        },\n",
    "        dtrain,\n",
    "        num_boost_round=300\n",
    "    )\n",
    "\n",
    "    pollutant_models[col] = model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4c67b2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPORAL_COLS = [\n",
    "    \"month_sin\",\"month_cos\",\n",
    "    \"doy_sin\",\"doy_cos\",\n",
    "    \"dow_sin\",\"dow_cos\",\n",
    "]\n",
    "\n",
    "ISPU_FEATURES = (\n",
    "    POLLUTANT_COLS +\n",
    "    WEATHER_COLS +\n",
    "    TEMPORAL_COLS +\n",
    "    [\"target_lag1\", \"target_lag2\", \"target_roll7\"] +\n",
    "    [\"lokasi_enc\"]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1539d01c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Direct Macro-F1: 0.5298\n",
      "✅ submission_direct.csv siap upload\n"
     ]
    }
   ],
   "source": [
    "# =====================================================\n",
    "# DIRECT MULTI-HORIZON ISPU — FINAL CLEAN VERSION\n",
    "# =====================================================\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "HORIZON = 7\n",
    "FEATURES_DIRECT = ISPU_FEATURES + [\"horizon\"]\n",
    "\n",
    "# -------------------------------\n",
    "# BUILD DATASET DIRECT\n",
    "# -------------------------------\n",
    "def build_direct(df, horizon):\n",
    "    rows = []\n",
    "\n",
    "    for loc, g in df.groupby(\"lokasi_clean\"):\n",
    "        g = g.sort_values(\"tanggal\").reset_index(drop=True)\n",
    "\n",
    "        for i in range(len(g) - horizon):\n",
    "            base = g.iloc[i]\n",
    "\n",
    "            for h in range(1, horizon + 1):\n",
    "                target = g.iloc[i + h][\"target\"]\n",
    "\n",
    "                feat = base[ISPU_FEATURES].to_dict()\n",
    "                feat[\"horizon\"] = h\n",
    "                feat[\"target\"] = target\n",
    "\n",
    "                rows.append(feat)\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "train_direct = build_direct(train_df, HORIZON)\n",
    "valid_direct = build_direct(valid_df, HORIZON)\n",
    "\n",
    "X_train = train_direct[FEATURES_DIRECT]\n",
    "y_train = train_direct[\"target\"]\n",
    "\n",
    "X_valid = valid_direct[FEATURES_DIRECT]\n",
    "y_valid = valid_direct[\"target\"]\n",
    "\n",
    "# -------------------------------\n",
    "# CLASS WEIGHT\n",
    "# -------------------------------\n",
    "classes = np.array([0, 1, 2])\n",
    "cw = compute_class_weight(\"balanced\", classes=classes, y=y_train)\n",
    "cw_dict = dict(zip(classes, cw))\n",
    "sample_weights = y_train.map(cw_dict).values\n",
    "\n",
    "# -------------------------------\n",
    "# TRAIN MODEL\n",
    "# -------------------------------\n",
    "dtrain = lgb.Dataset(X_train, label=y_train, weight=sample_weights)\n",
    "dvalid = lgb.Dataset(X_valid, label=y_valid)\n",
    "\n",
    "params = {\n",
    "    \"objective\": \"multiclass\",\n",
    "    \"num_class\": 3,\n",
    "    \"learning_rate\": 0.03,\n",
    "    \"num_leaves\": 63,\n",
    "    \"min_data_in_leaf\": 40,\n",
    "    \"feature_fraction\": 0.85,\n",
    "    \"bagging_fraction\": 0.85,\n",
    "    \"bagging_freq\": 1,\n",
    "    \"verbosity\": -1,\n",
    "    \"seed\": 42,\n",
    "}\n",
    "\n",
    "direct_model = lgb.train(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=700,\n",
    "    valid_sets=[dvalid],\n",
    "    callbacks=[lgb.log_evaluation(0)]  # silent\n",
    ")\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# VALIDASI\n",
    "# -------------------------------\n",
    "probs = direct_model.predict(X_valid)\n",
    "preds = np.argmax(probs, axis=1)\n",
    "\n",
    "print(\"Direct Macro-F1:\", round(f1_score(y_valid, preds, average=\"macro\"), 4))\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# INFERENCE SUBMISSION (FINAL FIXED)\n",
    "# =====================================================\n",
    "sub = pd.read_csv(\"sample_submission.csv\")\n",
    "\n",
    "sub[\"tanggal\"] = pd.to_datetime(sub[\"id\"].str.split(\"_\").str[0])\n",
    "sub[\"lokasi_clean\"] = sub[\"id\"].str.split(\"_\").str[1]\n",
    "\n",
    "results = []\n",
    "\n",
    "for loc in sub[\"lokasi_clean\"].unique():\n",
    "\n",
    "    # ===== history polutan =====\n",
    "    hist_pol = (\n",
    "        df_model[df_model[\"lokasi_clean\"] == loc]\n",
    "        .sort_values(\"tanggal\")\n",
    "        .iloc[-3:][POLLUTANT_COLS]\n",
    "        .values.tolist()\n",
    "    )\n",
    "\n",
    "    # ===== last feature row =====\n",
    "    last_row = (\n",
    "        df_model[df_model[\"lokasi_clean\"] == loc]\n",
    "        .sort_values(\"tanggal\")\n",
    "        .iloc[-1]\n",
    "    )\n",
    "\n",
    "    future = sub[sub[\"lokasi_clean\"] == loc].sort_values(\"tanggal\")\n",
    "\n",
    "    for h, (_, row) in enumerate(future.iterrows(), start=1):\n",
    "\n",
    "        # -------------------------\n",
    "        # 1. FORECAST POLLUTAN\n",
    "        # -------------------------\n",
    "        feat_f = {\n",
    "            \"month\": row[\"tanggal\"].month,\n",
    "            \"dayofyear\": row[\"tanggal\"].dayofyear,\n",
    "            \"dayofweek\": row[\"tanggal\"].dayofweek,\n",
    "            \"lokasi_enc\": le_loc.transform([loc])[0],\n",
    "        }\n",
    "\n",
    "        for i, col in enumerate(POLLUTANT_COLS):\n",
    "            feat_f[f\"{col}_lag1\"] = hist_pol[-1][i]\n",
    "            feat_f[f\"{col}_lag2\"] = hist_pol[-2][i]\n",
    "            feat_f[f\"{col}_lag3\"] = hist_pol[-3][i]\n",
    "\n",
    "        Xf = pd.DataFrame([feat_f])\n",
    "\n",
    "        new_pol = []\n",
    "        for col in POLLUTANT_COLS:\n",
    "            p = pollutant_models[col].predict(Xf)[0]\n",
    "            p = np.clip(p, 0, train_df[col].quantile(0.995))\n",
    "            new_pol.append(p)\n",
    "\n",
    "        hist_pol.append(new_pol)\n",
    "        hist_pol.pop(0)\n",
    "\n",
    "        # -------------------------\n",
    "        # 2. BUILD DIRECT FEATURES\n",
    "        # -------------------------\n",
    "        feat = last_row[ISPU_FEATURES].to_dict()\n",
    "\n",
    "        tgl = row[\"tanggal\"]\n",
    "\n",
    "        feat[\"month_sin\"] = np.sin(2*np.pi*tgl.month/12)\n",
    "        feat[\"month_cos\"] = np.cos(2*np.pi*tgl.month/12)\n",
    "\n",
    "        feat[\"doy_sin\"] = np.sin(2*np.pi*tgl.dayofyear/365)\n",
    "        feat[\"doy_cos\"] = np.cos(2*np.pi*tgl.dayofyear/365)\n",
    "\n",
    "        feat[\"dow_sin\"] = np.sin(2*np.pi*tgl.dayofweek/7)\n",
    "        feat[\"dow_cos\"] = np.cos(2*np.pi*tgl.dayofweek/7)\n",
    "\n",
    "\n",
    "        for i, col in enumerate(POLLUTANT_COLS):\n",
    "            feat[col] = new_pol[i]\n",
    "\n",
    "        feat[\"horizon\"] = min(h, HORIZON)\n",
    "\n",
    "        Xi = pd.DataFrame([feat])[FEATURES_DIRECT]\n",
    "\n",
    "        # -------------------------\n",
    "        # 3. PREDICT ISPU\n",
    "        # -------------------------\n",
    "        prob = direct_model.predict(Xi)[0]\n",
    "        pred = int(np.argmax(prob))\n",
    "\n",
    "        results.append(pred)\n",
    "\n",
    "# -------------------------------\n",
    "# SAVE SUBMISSION\n",
    "# -------------------------------\n",
    "INV_LABEL_MAP = {0: \"BAIK\", 1: \"SEDANG\", 2: \"TIDAK SEHAT\"}\n",
    "\n",
    "sub[\"kategori\"] = [INV_LABEL_MAP[p] for p in results]\n",
    "sub[[\"id\", \"kategori\"]].to_csv(\"submission_direct.csv\", index=False)\n",
    "\n",
    "print(\"✅ submission_direct.csv siap upload\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
