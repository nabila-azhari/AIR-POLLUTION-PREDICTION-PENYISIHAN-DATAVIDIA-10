{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "701632a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "PATH = Path(\"merged_libur_cuaca_ispu_ndvi.csv\")\n",
    "\n",
    "df = pd.read_csv(PATH, sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ebc3927d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_22400\\3085690969.py:24: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.groupby(\"lokasi_clean\", group_keys=False).apply(reindex_daily)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tanggal</th>\n",
       "      <th>periode_data</th>\n",
       "      <th>pm_sepuluh</th>\n",
       "      <th>pm_duakomalima</th>\n",
       "      <th>sulfur_dioksida</th>\n",
       "      <th>karbon_monoksida</th>\n",
       "      <th>ozon</th>\n",
       "      <th>nitrogen_dioksida</th>\n",
       "      <th>kategori</th>\n",
       "      <th>temperature_2m_max (°C)</th>\n",
       "      <th>...</th>\n",
       "      <th>pm25_missing</th>\n",
       "      <th>month</th>\n",
       "      <th>dayofyear</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>month_sin</th>\n",
       "      <th>month_cos</th>\n",
       "      <th>doy_sin</th>\n",
       "      <th>doy_cos</th>\n",
       "      <th>dow_sin</th>\n",
       "      <th>dow_cos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>201001.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>SEDANG</td>\n",
       "      <td>29.4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.017213</td>\n",
       "      <td>0.999852</td>\n",
       "      <td>-0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-01-02</td>\n",
       "      <td>201001.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>BAIK</td>\n",
       "      <td>30.8</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.034422</td>\n",
       "      <td>0.999407</td>\n",
       "      <td>-0.974928</td>\n",
       "      <td>-0.222521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-01-03</td>\n",
       "      <td>201001.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>BAIK</td>\n",
       "      <td>30.4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.051620</td>\n",
       "      <td>0.998667</td>\n",
       "      <td>-0.781831</td>\n",
       "      <td>0.623490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>201001.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>BAIK</td>\n",
       "      <td>30.3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.068802</td>\n",
       "      <td>0.997630</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-01-05</td>\n",
       "      <td>201001.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>BAIK</td>\n",
       "      <td>29.9</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.085965</td>\n",
       "      <td>0.996298</td>\n",
       "      <td>0.781831</td>\n",
       "      <td>0.623490</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     tanggal  periode_data  pm_sepuluh  pm_duakomalima  sulfur_dioksida  \\\n",
       "0 2010-01-01      201001.0        60.0            73.0              4.0   \n",
       "1 2010-01-02      201001.0        32.0            73.0              2.0   \n",
       "2 2010-01-03      201001.0        27.0            73.0              2.0   \n",
       "3 2010-01-04      201001.0        22.0            73.0              2.0   \n",
       "4 2010-01-05      201001.0        25.0            73.0              2.0   \n",
       "\n",
       "   karbon_monoksida  ozon  nitrogen_dioksida kategori  \\\n",
       "0              73.0  27.0               14.0   SEDANG   \n",
       "1              16.0  33.0                9.0     BAIK   \n",
       "2              19.0  20.0                9.0     BAIK   \n",
       "3              16.0  15.0                6.0     BAIK   \n",
       "4              17.0  15.0                8.0     BAIK   \n",
       "\n",
       "   temperature_2m_max (°C)  ...  pm25_missing  month  dayofyear  dayofweek  \\\n",
       "0                     29.4  ...             1      1          1          4   \n",
       "1                     30.8  ...             1      1          2          5   \n",
       "2                     30.4  ...             1      1          3          6   \n",
       "3                     30.3  ...             1      1          4          0   \n",
       "4                     29.9  ...             1      1          5          1   \n",
       "\n",
       "   month_sin  month_cos   doy_sin   doy_cos   dow_sin   dow_cos  \n",
       "0        0.5   0.866025  0.017213  0.999852 -0.433884 -0.900969  \n",
       "1        0.5   0.866025  0.034422  0.999407 -0.974928 -0.222521  \n",
       "2        0.5   0.866025  0.051620  0.998667 -0.781831  0.623490  \n",
       "3        0.5   0.866025  0.068802  0.997630  0.000000  1.000000  \n",
       "4        0.5   0.866025  0.085965  0.996298  0.781831  0.623490  \n",
       "\n",
       "[5 rows x 46 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parse tanggal\n",
    "df[\"tanggal\"] = pd.to_datetime(df[\"tanggal\"], dayfirst=True)\n",
    "\n",
    "# sort\n",
    "df = df.sort_values([\"lokasi_clean\", \"tanggal\"]).reset_index(drop=True)\n",
    "\n",
    "# drop kolom\n",
    "DROP_COLS = [\"max\", \"parameter_pencemar_kritis\", \"time\", \"id\", \"stasiun\"]\n",
    "df = df.drop(columns=DROP_COLS, errors=\"ignore\")\n",
    "\n",
    "# label mapping\n",
    "LABEL_MAP = {\"BAIK\": 0, \"SEDANG\": 1, \"TIDAK SEHAT\": 2}\n",
    "df = df[df[\"kategori\"].notna()].copy()\n",
    "df[\"target\"] = df[\"kategori\"].map(LABEL_MAP).astype(int)\n",
    "\n",
    "\n",
    "# REINDEX \n",
    "def reindex_daily(g):\n",
    "    idx = pd.date_range(g[\"tanggal\"].min(), g[\"tanggal\"].max(), freq=\"D\")\n",
    "    g = g.set_index(\"tanggal\").reindex(idx)\n",
    "    g[\"lokasi_clean\"] = g[\"lokasi_clean\"].iloc[0]\n",
    "    return g.reset_index().rename(columns={\"index\": \"tanggal\"})\n",
    "\n",
    "df = df.groupby(\"lokasi_clean\", group_keys=False).apply(reindex_daily)\n",
    "\n",
    "\n",
    "# PM2.5 HANDLING\n",
    "df[\"pm25_missing\"] = df[\"pm_duakomalima\"].isna().astype(int)\n",
    "\n",
    "median_pm25 = (\n",
    "    df[df[\"tanggal\"] >= \"2021-01-01\"]\n",
    "    .groupby(\"lokasi_clean\")[\"pm_duakomalima\"]\n",
    "    .median()\n",
    ")\n",
    "\n",
    "df[\"pm_duakomalima\"] = df[\"pm_duakomalima\"].fillna(\n",
    "    df[\"lokasi_clean\"].map(median_pm25)\n",
    ")\n",
    "\n",
    "\n",
    "# buang baris tanpa target (penting untuk training)\n",
    "df = df[df[\"target\"].notna()].copy()\n",
    "\n",
    "\n",
    "# TIME FEATURES \n",
    "df[\"month\"] = df[\"tanggal\"].dt.month\n",
    "df[\"dayofyear\"] = df[\"tanggal\"].dt.dayofyear\n",
    "df[\"dayofweek\"] = df[\"tanggal\"].dt.dayofweek\n",
    "\n",
    "df[\"month_sin\"] = np.sin(2*np.pi*df[\"month\"]/12)\n",
    "df[\"month_cos\"] = np.cos(2*np.pi*df[\"month\"]/12)\n",
    "\n",
    "df[\"doy_sin\"] = np.sin(2*np.pi*df[\"dayofyear\"]/365)\n",
    "df[\"doy_cos\"] = np.cos(2*np.pi*df[\"dayofyear\"]/365)\n",
    "\n",
    "df[\"dow_sin\"] = np.sin(2*np.pi*df[\"dayofweek\"]/7)\n",
    "df[\"dow_cos\"] = np.cos(2*np.pi*df[\"dayofweek\"]/7)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3acff62a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_22400\\759381649.py:39: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.groupby(\"lokasi_clean\", group_keys=False).apply(create_temporal_features)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_22400\\759381649.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_isnan\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_22400\\759381649.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_isnan\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_22400\\759381649.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_isnan\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_22400\\759381649.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_isnan\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_22400\\759381649.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_isnan\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_22400\\759381649.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_isnan\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_22400\\759381649.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_isnan\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_22400\\759381649.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_isnan\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_22400\\759381649.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_isnan\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_22400\\759381649.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_isnan\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_22400\\759381649.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_isnan\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_22400\\759381649.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_isnan\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_22400\\759381649.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_isnan\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_22400\\759381649.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_isnan\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_22400\\759381649.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_isnan\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_22400\\759381649.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_isnan\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_22400\\759381649.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_isnan\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_22400\\759381649.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_isnan\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_22400\\759381649.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_isnan\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_22400\\759381649.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_isnan\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_22400\\759381649.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_isnan\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_22400\\759381649.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_isnan\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_22400\\759381649.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_isnan\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_22400\\759381649.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_isnan\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_22400\\759381649.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_isnan\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_22400\\759381649.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_isnan\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_22400\\759381649.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_isnan\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_22400\\759381649.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_isnan\"] = df[col].isna().astype(int)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tanggal</th>\n",
       "      <th>periode_data</th>\n",
       "      <th>pm_sepuluh</th>\n",
       "      <th>pm_duakomalima</th>\n",
       "      <th>sulfur_dioksida</th>\n",
       "      <th>karbon_monoksida</th>\n",
       "      <th>ozon</th>\n",
       "      <th>nitrogen_dioksida</th>\n",
       "      <th>kategori</th>\n",
       "      <th>temperature_2m_max (°C)</th>\n",
       "      <th>...</th>\n",
       "      <th>nitrogen_dioksida_roll_mean_7_isnan</th>\n",
       "      <th>nitrogen_dioksida_roll_std_7_isnan</th>\n",
       "      <th>sulfur_dioksida_roll_mean_3_isnan</th>\n",
       "      <th>sulfur_dioksida_roll_std_3_isnan</th>\n",
       "      <th>sulfur_dioksida_roll_mean_7_isnan</th>\n",
       "      <th>sulfur_dioksida_roll_std_7_isnan</th>\n",
       "      <th>karbon_monoksida_roll_mean_3_isnan</th>\n",
       "      <th>karbon_monoksida_roll_std_3_isnan</th>\n",
       "      <th>karbon_monoksida_roll_mean_7_isnan</th>\n",
       "      <th>karbon_monoksida_roll_std_7_isnan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>201001.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>SEDANG</td>\n",
       "      <td>29.4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-01-02</td>\n",
       "      <td>201001.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>BAIK</td>\n",
       "      <td>30.8</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-01-03</td>\n",
       "      <td>201001.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>BAIK</td>\n",
       "      <td>30.4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>201001.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>BAIK</td>\n",
       "      <td>30.3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-01-05</td>\n",
       "      <td>201001.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>BAIK</td>\n",
       "      <td>29.9</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 166 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     tanggal  periode_data  pm_sepuluh  pm_duakomalima  sulfur_dioksida  \\\n",
       "0 2010-01-01      201001.0        60.0            73.0              4.0   \n",
       "1 2010-01-02      201001.0        32.0            73.0              2.0   \n",
       "2 2010-01-03      201001.0        27.0            73.0              2.0   \n",
       "3 2010-01-04      201001.0        22.0            73.0              2.0   \n",
       "4 2010-01-05      201001.0        25.0            73.0              2.0   \n",
       "\n",
       "   karbon_monoksida  ozon  nitrogen_dioksida kategori  \\\n",
       "0              73.0  27.0               14.0   SEDANG   \n",
       "1              16.0  33.0                9.0     BAIK   \n",
       "2              19.0  20.0                9.0     BAIK   \n",
       "3              16.0  15.0                6.0     BAIK   \n",
       "4              17.0  15.0                8.0     BAIK   \n",
       "\n",
       "   temperature_2m_max (°C)  ...  nitrogen_dioksida_roll_mean_7_isnan  \\\n",
       "0                     29.4  ...                                    1   \n",
       "1                     30.8  ...                                    1   \n",
       "2                     30.4  ...                                    1   \n",
       "3                     30.3  ...                                    1   \n",
       "4                     29.9  ...                                    1   \n",
       "\n",
       "   nitrogen_dioksida_roll_std_7_isnan  sulfur_dioksida_roll_mean_3_isnan  \\\n",
       "0                                   1                                  1   \n",
       "1                                   1                                  1   \n",
       "2                                   1                                  1   \n",
       "3                                   1                                  0   \n",
       "4                                   1                                  0   \n",
       "\n",
       "   sulfur_dioksida_roll_std_3_isnan  sulfur_dioksida_roll_mean_7_isnan  \\\n",
       "0                                 1                                  1   \n",
       "1                                 1                                  1   \n",
       "2                                 1                                  1   \n",
       "3                                 0                                  1   \n",
       "4                                 0                                  1   \n",
       "\n",
       "   sulfur_dioksida_roll_std_7_isnan  karbon_monoksida_roll_mean_3_isnan  \\\n",
       "0                                 1                                   1   \n",
       "1                                 1                                   1   \n",
       "2                                 1                                   1   \n",
       "3                                 1                                   0   \n",
       "4                                 1                                   0   \n",
       "\n",
       "   karbon_monoksida_roll_std_3_isnan  karbon_monoksida_roll_mean_7_isnan  \\\n",
       "0                                  1                                   1   \n",
       "1                                  1                                   1   \n",
       "2                                  1                                   1   \n",
       "3                                  0                                   1   \n",
       "4                                  0                                   1   \n",
       "\n",
       "   karbon_monoksida_roll_std_7_isnan  \n",
       "0                                  1  \n",
       "1                                  1  \n",
       "2                                  1  \n",
       "3                                  1  \n",
       "4                                  1  \n",
       "\n",
       "[5 rows x 166 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitur lag dan rolling\n",
    "\n",
    "POLLUTANT_COLS = [\n",
    "    \"pm_sepuluh\",\n",
    "    \"pm_duakomalima\",\n",
    "    \"ozon\",\n",
    "    \"nitrogen_dioksida\",\n",
    "    \"sulfur_dioksida\",\n",
    "    \"karbon_monoksida\",\n",
    "]\n",
    "\n",
    "WEATHER_COLS = [\n",
    "    \"temperature_2m_mean (°C)\",\n",
    "    \"relative_humidity_2m_mean (%)\",\n",
    "    \"wind_speed_10m_mean (km/h)\",\n",
    "    \"precipitation_sum (mm)\",\n",
    "    \"cloud_cover_mean (%)\",\n",
    "    \"surface_pressure_mean (hPa)\",\n",
    "]\n",
    "\n",
    "LAG_FEATURES = POLLUTANT_COLS + WEATHER_COLS\n",
    "\n",
    "LAGS = [1, 2, 3]\n",
    "ROLL_WINDOWS = [3, 7]\n",
    "def create_temporal_features(g):\n",
    "    g = g.sort_values(\"tanggal\")\n",
    "    for col in LAG_FEATURES:\n",
    "        for lag in LAGS:\n",
    "            g[f\"{col}_lag_{lag}\"] = g[col].shift(lag)\n",
    "\n",
    "\n",
    "    for col in POLLUTANT_COLS:\n",
    "        for w in ROLL_WINDOWS:\n",
    "            g[f\"{col}_roll_mean_{w}\"] = g[col].shift(1).rolling(w).mean()\n",
    "            g[f\"{col}_roll_std_{w}\"]  = g[col].shift(1).rolling(w).std()\n",
    "\n",
    "    return g\n",
    "\n",
    "df = df.groupby(\"lokasi_clean\", group_keys=False).apply(create_temporal_features)\n",
    "lag_cols = [c for c in df.columns if \"lag_\" in c or \"roll_\" in c]\n",
    "\n",
    "for col in lag_cols:\n",
    "    df[f\"{col}_isnan\"] = df[col].isna().astype(int)\n",
    "\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5b7f9681",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_model = df.dropna(subset=[\"target\"]).reset_index(drop=True)\n",
    "\n",
    "H = 30\n",
    "\n",
    "rows = []\n",
    "\n",
    "for loc, g in df_model.groupby(\"lokasi_clean\"):\n",
    "    g = g.sort_values(\"tanggal\").reset_index(drop=True)\n",
    "\n",
    "    # precompute lag sekali saja\n",
    "    for col in POLLUTANT_COLS:\n",
    "        g[f\"{col}_lag1\"] = g[col].shift(0)\n",
    "        g[f\"{col}_lag2\"] = g[col].shift(1)\n",
    "        g[f\"{col}_lag3\"] = g[col].shift(2)\n",
    "\n",
    "    for h in range(1, H + 1):\n",
    "        g_future = g.shift(-h)\n",
    "\n",
    "        temp = pd.DataFrame({\n",
    "            \"lokasi_clean\": loc,\n",
    "            \"tanggal\": g[\"tanggal\"],\n",
    "            \"horizon\": h,\n",
    "            \"month\": g[\"tanggal\"].dt.month,\n",
    "            \"dayofyear\": g[\"tanggal\"].dt.dayofyear,\n",
    "            \"dayofweek\": g[\"tanggal\"].dt.dayofweek,\n",
    "        })\n",
    "\n",
    "        # fitur lag\n",
    "        for col in POLLUTANT_COLS:\n",
    "            temp[f\"{col}_lag1\"] = g[f\"{col}_lag1\"]\n",
    "            temp[f\"{col}_lag2\"] = g[f\"{col}_lag2\"]\n",
    "            temp[f\"{col}_lag3\"] = g[f\"{col}_lag3\"]\n",
    "\n",
    "        # target masa depan\n",
    "        for col in POLLUTANT_COLS:\n",
    "            temp[f\"target_{col}\"] = g_future[col]\n",
    "\n",
    "        rows.append(temp)\n",
    "\n",
    "df_forecast = pd.concat(rows, ignore_index=True).dropna().reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le_loc = LabelEncoder()\n",
    "df_model[\"lokasi_enc\"] = le_loc.fit_transform(df_model[\"lokasi_clean\"])\n",
    "\n",
    "df_forecast[\"lokasi_enc\"] = le_loc.transform(df_forecast[\"lokasi_clean\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "11bf470a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "pollutant_models = {}\n",
    "\n",
    "FEATURES_F = [\n",
    "    c for c in df_forecast.columns\n",
    "    if c.startswith(tuple(POLLUTANT_COLS))\n",
    "    or c in [\"month\", \"dayofyear\", \"dayofweek\", \"lokasi_enc\", \"horizon\"]\n",
    "]\n",
    "\n",
    "for col in POLLUTANT_COLS:\n",
    "\n",
    "    y_col = f\"target_{col}\"\n",
    "\n",
    "    Xf = df_forecast[FEATURES_F]\n",
    "    yf = df_forecast[y_col]\n",
    "\n",
    "    train_data = lgb.Dataset(Xf, label=yf)\n",
    "\n",
    "    params = {\n",
    "        \"objective\": \"regression\",\n",
    "        \"metric\": \"l2\",\n",
    "        \"learning_rate\": 0.05,\n",
    "        \"num_leaves\": 64,\n",
    "        \"verbosity\": -1,\n",
    "        \"seed\": 42,\n",
    "    }\n",
    "\n",
    "    model = lgb.train(params, train_data, num_boost_round=500)\n",
    "    pollutant_models[col] = model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c489b00e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(455085, 31)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2de08805",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le_loc = LabelEncoder()\n",
    "df_model[\"lokasi_enc\"] = le_loc.fit_transform(df_model[\"lokasi_clean\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0d881e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ ISPU model trained\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "ISPU_FEATURES = POLLUTANT_COLS + [\n",
    "    \"month\", \"dayofyear\", \"dayofweek\",\n",
    "    \"lokasi_enc\"\n",
    "]\n",
    "\n",
    "X_ispu = df_model[ISPU_FEATURES]\n",
    "y_ispu = df_model[\"target\"]\n",
    "\n",
    "train_data = lgb.Dataset(X_ispu, label=y_ispu)\n",
    "\n",
    "ISPU_PARAMS = {\n",
    "    \"objective\": \"multiclass\",\n",
    "    \"num_class\": 3,\n",
    "    \"metric\": \"None\",\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"num_leaves\": 63,\n",
    "    \"min_data_in_leaf\": 40,\n",
    "    \"feature_fraction\": 0.8,\n",
    "    \"bagging_fraction\": 0.8,\n",
    "    \"bagging_freq\": 5,\n",
    "    \"verbosity\": -1,\n",
    "    \"seed\": 42,\n",
    "    \"class_weight\": \"balanced\"\n",
    "}\n",
    "\n",
    "\n",
    "ispu_model = lgb.train(ISPU_PARAMS, train_data, num_boost_round=500)\n",
    "\n",
    "print(\"✅ ISPU model trained\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f1976022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold: [0.2, 0.2, 0.2]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "probs = ispu_model.predict(X_ispu)\n",
    "best_t = [0.33, 0.33, 0.33]\n",
    "\n",
    "for c in range(3):\n",
    "    best_f1 = 0\n",
    "    for t in np.linspace(0.2, 0.6, 25):\n",
    "        pred = probs.argmax(1)\n",
    "        pred[probs[:, c] > t] = c\n",
    "        f1 = f1_score(y_ispu, pred, average=\"macro\")\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_t[c] = t\n",
    "\n",
    "print(\"Best threshold:\", best_t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c1a12ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv(\"sample_submission.csv\")\n",
    "\n",
    "sub[\"tanggal\"] = pd.to_datetime(sub[\"id\"].str.split(\"_\").str[0])\n",
    "sub[\"lokasi_clean\"] = sub[\"id\"].str.split(\"_\").str[1]\n",
    "sub = sub.sort_values([\"lokasi_clean\", \"tanggal\"]).reset_index(drop=True)\n",
    "\n",
    "sub[\"lokasi_enc\"] = le_loc_f.transform(sub[\"lokasi_clean\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f766fe93",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_rows = []\n",
    "\n",
    "for loc in sub[\"lokasi_clean\"].unique():\n",
    "\n",
    "    # ===== riwayat 3 hari terakhir =====\n",
    "    hist = (\n",
    "        df_model[df_model[\"lokasi_clean\"] == loc]\n",
    "        .sort_values(\"tanggal\")\n",
    "        .iloc[-3:][POLLUTANT_COLS]\n",
    "        .values.tolist()\n",
    "    )\n",
    "\n",
    "    future_rows = (\n",
    "        sub[sub[\"lokasi_clean\"] == loc]\n",
    "        .sort_values(\"tanggal\")\n",
    "    )\n",
    "\n",
    "    for _, row in future_rows.iterrows():\n",
    "\n",
    "        tgl = row[\"tanggal\"]\n",
    "\n",
    "        # ===== fitur forecast =====\n",
    "        feat = {\n",
    "            \"horizon\": 1,  # autoregressive → selalu 1-step\n",
    "            \"month\": tgl.month,\n",
    "            \"dayofyear\": tgl.dayofyear,\n",
    "            \"dayofweek\": tgl.dayofweek,\n",
    "            \"lokasi_enc\": row[\"lokasi_enc\"],\n",
    "        }\n",
    "\n",
    "        # ===== lag dari history rolling =====\n",
    "        for i, col in enumerate(POLLUTANT_COLS):\n",
    "            feat[f\"{col}_lag1\"] = hist[-1][i]\n",
    "            feat[f\"{col}_lag2\"] = hist[-2][i]\n",
    "            feat[f\"{col}_lag3\"] = hist[-3][i]\n",
    "\n",
    "        Xf = pd.DataFrame([feat])\n",
    "\n",
    "        # ===== prediksi semua polutan =====\n",
    "        new_vals = []\n",
    "        preds_pol = {}\n",
    "\n",
    "        for i, col in enumerate(POLLUTANT_COLS):\n",
    "            pred = pollutant_models[col].predict(Xf)[0]\n",
    "            new_vals.append(pred)\n",
    "            preds_pol[col] = pred\n",
    "\n",
    "        # ===== update history (rolling window) =====\n",
    "        hist.append(new_vals)\n",
    "        hist.pop(0)\n",
    "\n",
    "        # ===== simpan =====\n",
    "        feat.update(preds_pol)\n",
    "        feat[\"id\"] = row[\"id\"]\n",
    "\n",
    "        forecast_rows.append(feat)\n",
    "\n",
    "df_future = pd.DataFrame(forecast_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "56375d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "sub = pd.read_csv(\"sample_submission.csv\")\n",
    "\n",
    "sub[\"tanggal\"] = pd.to_datetime(sub[\"id\"].str.split(\"_\").str[0])\n",
    "sub[\"lokasi_clean\"] = sub[\"id\"].str.split(\"_\").str[1]\n",
    "\n",
    "sub = sub.sort_values([\"lokasi_clean\", \"tanggal\"]).reset_index(drop=True)\n",
    "\n",
    "# encode lokasi (PASTI sama dengan df_model)\n",
    "sub[\"lokasi_enc\"] = le_loc.transform(sub[\"lokasi_clean\"])\n",
    "\n",
    "# tanggal terakhir di data training per lokasi\n",
    "last_dates = (\n",
    "    df_model.groupby(\"lokasi_clean\")[\"tanggal\"]\n",
    "    .max()\n",
    "    .to_dict()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ca3b682f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for _, row in df_future.iterrows():\n",
    "\n",
    "    feat_ispu = {\n",
    "        col: row[col] for col in POLLUTANT_COLS\n",
    "    }\n",
    "\n",
    "    feat_ispu.update({\n",
    "        \"month\": row[\"month\"],\n",
    "        \"dayofyear\": row[\"dayofyear\"],\n",
    "        \"dayofweek\": row[\"dayofweek\"],\n",
    "        \"lokasi_enc\": row[\"lokasi_enc\"],   \n",
    "    })\n",
    "\n",
    "    Xi = pd.DataFrame([feat_ispu])\n",
    "\n",
    "    prob = ispu_model.predict(Xi)\n",
    "    pred = prob.argmax(1)\n",
    "\n",
    "    for c, t in enumerate(best_t):\n",
    "        pred[prob[:, c] > t] = c\n",
    "\n",
    "    results.append(int(pred[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1496ec52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ submission_step4.csv siap upload\n"
     ]
    }
   ],
   "source": [
    "INV_LABEL_MAP = {0: \"BAIK\", 1: \"SEDANG\", 2: \"TIDAK SEHAT\"}\n",
    "\n",
    "sub_final = pd.read_csv(\"sample_submission.csv\")\n",
    "\n",
    "pred_df = df_future[[\"id\"]].copy()\n",
    "pred_df[\"kategori\"] = [INV_LABEL_MAP[i] for i in results]\n",
    "\n",
    "\n",
    "sub_final = sub_final.merge(pred_df, on=\"id\", how=\"left\")\n",
    "\n",
    "sub_final.to_csv(\"submission_step4.csv\", index=False)\n",
    "\n",
    "print(\"✅ submission_step4.csv siap upload\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6415659",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"submission_step4.csv\", sep=\";\")  \n",
    "df.to_csv(\"submission_step_4.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
