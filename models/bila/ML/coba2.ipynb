{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "701632a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "PATH = Path(\"merged_libur_cuaca_ispu_ndvi.csv\")\n",
    "\n",
    "df = pd.read_csv(PATH, sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebc3927d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_1312\\3085690969.py:24: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.groupby(\"lokasi_clean\", group_keys=False).apply(reindex_daily)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tanggal</th>\n",
       "      <th>periode_data</th>\n",
       "      <th>pm_sepuluh</th>\n",
       "      <th>pm_duakomalima</th>\n",
       "      <th>sulfur_dioksida</th>\n",
       "      <th>karbon_monoksida</th>\n",
       "      <th>ozon</th>\n",
       "      <th>nitrogen_dioksida</th>\n",
       "      <th>kategori</th>\n",
       "      <th>temperature_2m_max (°C)</th>\n",
       "      <th>...</th>\n",
       "      <th>pm25_missing</th>\n",
       "      <th>month</th>\n",
       "      <th>dayofyear</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>month_sin</th>\n",
       "      <th>month_cos</th>\n",
       "      <th>doy_sin</th>\n",
       "      <th>doy_cos</th>\n",
       "      <th>dow_sin</th>\n",
       "      <th>dow_cos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>201001.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>SEDANG</td>\n",
       "      <td>29.4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.017213</td>\n",
       "      <td>0.999852</td>\n",
       "      <td>-0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-01-02</td>\n",
       "      <td>201001.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>BAIK</td>\n",
       "      <td>30.8</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.034422</td>\n",
       "      <td>0.999407</td>\n",
       "      <td>-0.974928</td>\n",
       "      <td>-0.222521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-01-03</td>\n",
       "      <td>201001.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>BAIK</td>\n",
       "      <td>30.4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.051620</td>\n",
       "      <td>0.998667</td>\n",
       "      <td>-0.781831</td>\n",
       "      <td>0.623490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>201001.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>BAIK</td>\n",
       "      <td>30.3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.068802</td>\n",
       "      <td>0.997630</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-01-05</td>\n",
       "      <td>201001.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>BAIK</td>\n",
       "      <td>29.9</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.085965</td>\n",
       "      <td>0.996298</td>\n",
       "      <td>0.781831</td>\n",
       "      <td>0.623490</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     tanggal  periode_data  pm_sepuluh  pm_duakomalima  sulfur_dioksida  \\\n",
       "0 2010-01-01      201001.0        60.0            73.0              4.0   \n",
       "1 2010-01-02      201001.0        32.0            73.0              2.0   \n",
       "2 2010-01-03      201001.0        27.0            73.0              2.0   \n",
       "3 2010-01-04      201001.0        22.0            73.0              2.0   \n",
       "4 2010-01-05      201001.0        25.0            73.0              2.0   \n",
       "\n",
       "   karbon_monoksida  ozon  nitrogen_dioksida kategori  \\\n",
       "0              73.0  27.0               14.0   SEDANG   \n",
       "1              16.0  33.0                9.0     BAIK   \n",
       "2              19.0  20.0                9.0     BAIK   \n",
       "3              16.0  15.0                6.0     BAIK   \n",
       "4              17.0  15.0                8.0     BAIK   \n",
       "\n",
       "   temperature_2m_max (°C)  ...  pm25_missing  month  dayofyear  dayofweek  \\\n",
       "0                     29.4  ...             1      1          1          4   \n",
       "1                     30.8  ...             1      1          2          5   \n",
       "2                     30.4  ...             1      1          3          6   \n",
       "3                     30.3  ...             1      1          4          0   \n",
       "4                     29.9  ...             1      1          5          1   \n",
       "\n",
       "   month_sin  month_cos   doy_sin   doy_cos   dow_sin   dow_cos  \n",
       "0        0.5   0.866025  0.017213  0.999852 -0.433884 -0.900969  \n",
       "1        0.5   0.866025  0.034422  0.999407 -0.974928 -0.222521  \n",
       "2        0.5   0.866025  0.051620  0.998667 -0.781831  0.623490  \n",
       "3        0.5   0.866025  0.068802  0.997630  0.000000  1.000000  \n",
       "4        0.5   0.866025  0.085965  0.996298  0.781831  0.623490  \n",
       "\n",
       "[5 rows x 46 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parse tanggal\n",
    "df[\"tanggal\"] = pd.to_datetime(df[\"tanggal\"], dayfirst=True)\n",
    "\n",
    "# sort\n",
    "df = df.sort_values([\"lokasi_clean\", \"tanggal\"]).reset_index(drop=True)\n",
    "\n",
    "# drop kolom\n",
    "DROP_COLS = [\"max\", \"parameter_pencemar_kritis\", \"time\", \"id\", \"stasiun\"]\n",
    "df = df.drop(columns=DROP_COLS, errors=\"ignore\")\n",
    "\n",
    "# label mapping\n",
    "LABEL_MAP = {\"BAIK\": 0, \"SEDANG\": 1, \"TIDAK SEHAT\": 2}\n",
    "df = df[df[\"kategori\"].notna()].copy()\n",
    "df[\"target\"] = df[\"kategori\"].map(LABEL_MAP).astype(int)\n",
    "\n",
    "\n",
    "# REINDEX \n",
    "def reindex_daily(g):\n",
    "    idx = pd.date_range(g[\"tanggal\"].min(), g[\"tanggal\"].max(), freq=\"D\")\n",
    "    g = g.set_index(\"tanggal\").reindex(idx)\n",
    "    g[\"lokasi_clean\"] = g[\"lokasi_clean\"].iloc[0]\n",
    "    return g.reset_index().rename(columns={\"index\": \"tanggal\"})\n",
    "\n",
    "df = df.groupby(\"lokasi_clean\", group_keys=False).apply(reindex_daily)\n",
    "\n",
    "\n",
    "# PM2.5 HANDLING\n",
    "df[\"pm25_missing\"] = df[\"pm_duakomalima\"].isna().astype(int)\n",
    "\n",
    "median_pm25 = (\n",
    "    df[df[\"tanggal\"] >= \"2021-01-01\"]\n",
    "    .groupby(\"lokasi_clean\")[\"pm_duakomalima\"]\n",
    "    .median()\n",
    ")\n",
    "\n",
    "df[\"pm_duakomalima\"] = df[\"pm_duakomalima\"].fillna(\n",
    "    df[\"lokasi_clean\"].map(median_pm25)\n",
    ")\n",
    "\n",
    "\n",
    "# buang baris tanpa target (penting untuk training)\n",
    "df = df[df[\"target\"].notna()].copy()\n",
    "\n",
    "\n",
    "# TIME FEATURES \n",
    "df[\"month\"] = df[\"tanggal\"].dt.month\n",
    "df[\"dayofyear\"] = df[\"tanggal\"].dt.dayofyear\n",
    "df[\"dayofweek\"] = df[\"tanggal\"].dt.dayofweek\n",
    "\n",
    "df[\"month_sin\"] = np.sin(2*np.pi*df[\"month\"]/12)\n",
    "df[\"month_cos\"] = np.cos(2*np.pi*df[\"month\"]/12)\n",
    "\n",
    "df[\"doy_sin\"] = np.sin(2*np.pi*df[\"dayofyear\"]/365)\n",
    "df[\"doy_cos\"] = np.cos(2*np.pi*df[\"dayofyear\"]/365)\n",
    "\n",
    "df[\"dow_sin\"] = np.sin(2*np.pi*df[\"dayofweek\"]/7)\n",
    "df[\"dow_cos\"] = np.cos(2*np.pi*df[\"dayofweek\"]/7)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3acff62a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_1312\\759381649.py:39: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.groupby(\"lokasi_clean\", group_keys=False).apply(create_temporal_features)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_1312\\759381649.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_isnan\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_1312\\759381649.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_isnan\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_1312\\759381649.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_isnan\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_1312\\759381649.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_isnan\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_1312\\759381649.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_isnan\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_1312\\759381649.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_isnan\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_1312\\759381649.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_isnan\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_1312\\759381649.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_isnan\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_1312\\759381649.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_isnan\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_1312\\759381649.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_isnan\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_1312\\759381649.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_isnan\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_1312\\759381649.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_isnan\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_1312\\759381649.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_isnan\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_1312\\759381649.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_isnan\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_1312\\759381649.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_isnan\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_1312\\759381649.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_isnan\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_1312\\759381649.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_isnan\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_1312\\759381649.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_isnan\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_1312\\759381649.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_isnan\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_1312\\759381649.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_isnan\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_1312\\759381649.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_isnan\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_1312\\759381649.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_isnan\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_1312\\759381649.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_isnan\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_1312\\759381649.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_isnan\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_1312\\759381649.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_isnan\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_1312\\759381649.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_isnan\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_1312\\759381649.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_isnan\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_1312\\759381649.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_isnan\"] = df[col].isna().astype(int)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tanggal</th>\n",
       "      <th>periode_data</th>\n",
       "      <th>pm_sepuluh</th>\n",
       "      <th>pm_duakomalima</th>\n",
       "      <th>sulfur_dioksida</th>\n",
       "      <th>karbon_monoksida</th>\n",
       "      <th>ozon</th>\n",
       "      <th>nitrogen_dioksida</th>\n",
       "      <th>kategori</th>\n",
       "      <th>temperature_2m_max (°C)</th>\n",
       "      <th>...</th>\n",
       "      <th>nitrogen_dioksida_roll_mean_7_isnan</th>\n",
       "      <th>nitrogen_dioksida_roll_std_7_isnan</th>\n",
       "      <th>sulfur_dioksida_roll_mean_3_isnan</th>\n",
       "      <th>sulfur_dioksida_roll_std_3_isnan</th>\n",
       "      <th>sulfur_dioksida_roll_mean_7_isnan</th>\n",
       "      <th>sulfur_dioksida_roll_std_7_isnan</th>\n",
       "      <th>karbon_monoksida_roll_mean_3_isnan</th>\n",
       "      <th>karbon_monoksida_roll_std_3_isnan</th>\n",
       "      <th>karbon_monoksida_roll_mean_7_isnan</th>\n",
       "      <th>karbon_monoksida_roll_std_7_isnan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>201001.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>SEDANG</td>\n",
       "      <td>29.4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-01-02</td>\n",
       "      <td>201001.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>BAIK</td>\n",
       "      <td>30.8</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-01-03</td>\n",
       "      <td>201001.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>BAIK</td>\n",
       "      <td>30.4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>201001.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>BAIK</td>\n",
       "      <td>30.3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-01-05</td>\n",
       "      <td>201001.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>BAIK</td>\n",
       "      <td>29.9</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 166 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     tanggal  periode_data  pm_sepuluh  pm_duakomalima  sulfur_dioksida  \\\n",
       "0 2010-01-01      201001.0        60.0            73.0              4.0   \n",
       "1 2010-01-02      201001.0        32.0            73.0              2.0   \n",
       "2 2010-01-03      201001.0        27.0            73.0              2.0   \n",
       "3 2010-01-04      201001.0        22.0            73.0              2.0   \n",
       "4 2010-01-05      201001.0        25.0            73.0              2.0   \n",
       "\n",
       "   karbon_monoksida  ozon  nitrogen_dioksida kategori  \\\n",
       "0              73.0  27.0               14.0   SEDANG   \n",
       "1              16.0  33.0                9.0     BAIK   \n",
       "2              19.0  20.0                9.0     BAIK   \n",
       "3              16.0  15.0                6.0     BAIK   \n",
       "4              17.0  15.0                8.0     BAIK   \n",
       "\n",
       "   temperature_2m_max (°C)  ...  nitrogen_dioksida_roll_mean_7_isnan  \\\n",
       "0                     29.4  ...                                    1   \n",
       "1                     30.8  ...                                    1   \n",
       "2                     30.4  ...                                    1   \n",
       "3                     30.3  ...                                    1   \n",
       "4                     29.9  ...                                    1   \n",
       "\n",
       "   nitrogen_dioksida_roll_std_7_isnan  sulfur_dioksida_roll_mean_3_isnan  \\\n",
       "0                                   1                                  1   \n",
       "1                                   1                                  1   \n",
       "2                                   1                                  1   \n",
       "3                                   1                                  0   \n",
       "4                                   1                                  0   \n",
       "\n",
       "   sulfur_dioksida_roll_std_3_isnan  sulfur_dioksida_roll_mean_7_isnan  \\\n",
       "0                                 1                                  1   \n",
       "1                                 1                                  1   \n",
       "2                                 1                                  1   \n",
       "3                                 0                                  1   \n",
       "4                                 0                                  1   \n",
       "\n",
       "   sulfur_dioksida_roll_std_7_isnan  karbon_monoksida_roll_mean_3_isnan  \\\n",
       "0                                 1                                   1   \n",
       "1                                 1                                   1   \n",
       "2                                 1                                   1   \n",
       "3                                 1                                   0   \n",
       "4                                 1                                   0   \n",
       "\n",
       "   karbon_monoksida_roll_std_3_isnan  karbon_monoksida_roll_mean_7_isnan  \\\n",
       "0                                  1                                   1   \n",
       "1                                  1                                   1   \n",
       "2                                  1                                   1   \n",
       "3                                  0                                   1   \n",
       "4                                  0                                   1   \n",
       "\n",
       "   karbon_monoksida_roll_std_7_isnan  \n",
       "0                                  1  \n",
       "1                                  1  \n",
       "2                                  1  \n",
       "3                                  1  \n",
       "4                                  1  \n",
       "\n",
       "[5 rows x 166 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitur lag dan rolling\n",
    "\n",
    "POLLUTANT_COLS = [\n",
    "    \"pm_sepuluh\",\n",
    "    \"pm_duakomalima\",\n",
    "    \"ozon\",\n",
    "    \"nitrogen_dioksida\",\n",
    "    \"sulfur_dioksida\",\n",
    "    \"karbon_monoksida\",\n",
    "]\n",
    "\n",
    "WEATHER_COLS = [\n",
    "    \"temperature_2m_mean (°C)\",\n",
    "    \"relative_humidity_2m_mean (%)\",\n",
    "    \"wind_speed_10m_mean (km/h)\",\n",
    "    \"precipitation_sum (mm)\",\n",
    "    \"cloud_cover_mean (%)\",\n",
    "    \"surface_pressure_mean (hPa)\",\n",
    "]\n",
    "\n",
    "LAG_FEATURES = POLLUTANT_COLS + WEATHER_COLS\n",
    "\n",
    "LAGS = [1, 2, 3]\n",
    "ROLL_WINDOWS = [3, 7]\n",
    "def create_temporal_features(g):\n",
    "    g = g.sort_values(\"tanggal\")\n",
    "    for col in LAG_FEATURES:\n",
    "        for lag in LAGS:\n",
    "            g[f\"{col}_lag_{lag}\"] = g[col].shift(lag)\n",
    "\n",
    "\n",
    "    for col in POLLUTANT_COLS:\n",
    "        for w in ROLL_WINDOWS:\n",
    "            g[f\"{col}_roll_mean_{w}\"] = g[col].shift(1).rolling(w).mean()\n",
    "            g[f\"{col}_roll_std_{w}\"]  = g[col].shift(1).rolling(w).std()\n",
    "\n",
    "    return g\n",
    "\n",
    "df = df.groupby(\"lokasi_clean\", group_keys=False).apply(create_temporal_features)\n",
    "lag_cols = [c for c in df.columns if \"lag_\" in c or \"roll_\" in c]\n",
    "\n",
    "for col in lag_cols:\n",
    "    df[f\"{col}_isnan\"] = df[col].isna().astype(int)\n",
    "\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ff870a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_1312\\974700748.py:10: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_model = df_model.groupby(\"lokasi_clean\", group_keys=False).apply(make_target_lag)\n"
     ]
    }
   ],
   "source": [
    "df_model = df.dropna(subset=[\"target\"]).reset_index(drop=True)\n",
    "\n",
    "def make_target_lag(g):\n",
    "    g = g.sort_values(\"tanggal\")\n",
    "    g[\"target_lag1\"] = g[\"target\"].shift(1)\n",
    "    g[\"target_lag2\"] = g[\"target\"].shift(2)\n",
    "    g[\"target_roll7\"] = g[\"target\"].shift(1).rolling(7).mean()\n",
    "    return g\n",
    "\n",
    "df_model = df_model.groupby(\"lokasi_clean\", group_keys=False).apply(make_target_lag)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b7f9681",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_1312\\904045537.py:16: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  train_df = train_df.groupby(\"lokasi_clean\", group_keys=False).apply(make_lag_features)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_1312\\904045537.py:17: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  valid_df = valid_df.groupby(\"lokasi_clean\", group_keys=False).apply(make_lag_features)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "SPLIT_DATE = \"2024-01-01\"\n",
    "\n",
    "train_df = df_model[df_model[\"tanggal\"] < SPLIT_DATE].copy()\n",
    "valid_df = df_model[df_model[\"tanggal\"] >= SPLIT_DATE].copy()\n",
    "\n",
    "\n",
    "\n",
    "def make_lag_features(g):\n",
    "    g = g.sort_values(\"tanggal\")\n",
    "    for col in POLLUTANT_COLS:\n",
    "        g[f\"{col}_lag1\"] = g[col].shift(1)\n",
    "        g[f\"{col}_lag2\"] = g[col].shift(2)\n",
    "        g[f\"{col}_lag3\"] = g[col].shift(3)\n",
    "    return g\n",
    "\n",
    "train_df = train_df.groupby(\"lokasi_clean\", group_keys=False).apply(make_lag_features)\n",
    "valid_df = valid_df.groupby(\"lokasi_clean\", group_keys=False).apply(make_lag_features)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4abfdf56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode lokasi\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le_loc = LabelEncoder()\n",
    "train_df[\"lokasi_enc\"] = le_loc.fit_transform(train_df[\"lokasi_clean\"])\n",
    "valid_df[\"lokasi_enc\"] = le_loc.transform(valid_df[\"lokasi_clean\"])\n",
    "\n",
    "# fitur forecast\n",
    "FEATURES_F = (\n",
    "    [f\"{c}_lag1\" for c in POLLUTANT_COLS] +\n",
    "    [f\"{c}_lag2\" for c in POLLUTANT_COLS] +\n",
    "    [f\"{c}_lag3\" for c in POLLUTANT_COLS] +\n",
    "    [\"month\", \"dayofyear\", \"dayofweek\", \"lokasi_enc\"]\n",
    ")\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "pollutant_models = {}\n",
    "\n",
    "for col in POLLUTANT_COLS:\n",
    "    X = train_df[FEATURES_F]\n",
    "    y = train_df[col]\n",
    "\n",
    "    dtrain = lgb.Dataset(X, label=y)\n",
    "\n",
    "    model = lgb.train(\n",
    "        {\n",
    "            \"objective\": \"regression\",\n",
    "            \"metric\": \"l2\",\n",
    "            \"learning_rate\": 0.05,\n",
    "            \"num_leaves\": 64,\n",
    "            \"verbosity\": -1,\n",
    "            \"seed\": 42,\n",
    "        },\n",
    "        dtrain,\n",
    "        num_boost_round=300\n",
    "    )\n",
    "\n",
    "    pollutant_models[col] = model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b96bde77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forecast_autoreg(start_hist, future_dates, loc_enc):\n",
    "    hist = start_hist.copy()\n",
    "    rows = []\n",
    "\n",
    "    for tgl in future_dates:\n",
    "        feat = {\n",
    "            \"month\": tgl.month,\n",
    "            \"dayofyear\": tgl.dayofyear,\n",
    "            \"dayofweek\": tgl.dayofweek,\n",
    "            \"lokasi_enc\": loc_enc,\n",
    "        }\n",
    "\n",
    "        for i, col in enumerate(POLLUTANT_COLS):\n",
    "            feat[f\"{col}_lag1\"] = hist[-1][i]\n",
    "            feat[f\"{col}_lag2\"] = hist[-2][i]\n",
    "            feat[f\"{col}_lag3\"] = hist[-3][i]\n",
    "\n",
    "        Xf = pd.DataFrame([feat])\n",
    "\n",
    "        new_vals = []\n",
    "        for col in POLLUTANT_COLS:\n",
    "            pred = pollutant_models[col].predict(Xf)[0]\n",
    "            new_vals.append(pred)\n",
    "\n",
    "        hist.append(new_vals)\n",
    "        hist.pop(0)\n",
    "\n",
    "        feat.update(dict(zip(POLLUTANT_COLS, new_vals)))\n",
    "        rows.append(feat)\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "val_forecasts = []\n",
    "\n",
    "for loc in valid_df[\"lokasi_clean\"].unique():\n",
    "    hist = (\n",
    "        train_df[train_df[\"lokasi_clean\"] == loc]\n",
    "        .sort_values(\"tanggal\")\n",
    "        .iloc[-3:][POLLUTANT_COLS]\n",
    "        .values.tolist()\n",
    "    )\n",
    "\n",
    "    future_dates = valid_df[valid_df[\"lokasi_clean\"] == loc][\"tanggal\"]\n",
    "    loc_enc = le_loc.transform([loc])[0]\n",
    "\n",
    "    df_pred = forecast_autoreg(hist, future_dates, loc_enc)\n",
    "    df_pred[\"lokasi_clean\"] = loc\n",
    "    df_pred[\"tanggal\"] = future_dates.values\n",
    "\n",
    "    val_forecasts.append(df_pred)\n",
    "\n",
    "df_val_forecast = pd.concat(val_forecasts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d881e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# MERGE VALID + FORECAST\n",
    "# ===============================\n",
    "valid_merge = valid_df.merge(\n",
    "    df_val_forecast,\n",
    "    on=[\"lokasi_clean\", \"tanggal\"],\n",
    "    suffixes=(\"_true\", \"\")\n",
    ")\n",
    "\n",
    "# ===============================\n",
    "# TRAIN ISPU (PAKAI FORECASTED POLLUTANTS)\n",
    "# ===============================\n",
    "ISPU_FEATURES = POLLUTANT_COLS + [\n",
    "    \"month\",\"dayofyear\",\"dayofweek\",\"lokasi_enc\",\n",
    "    \"target_lag1\",\"target_lag2\",\"target_roll7\"\n",
    "]\n",
    "ISPU_FEATURES += WEATHER_COLS\n",
    "\n",
    "X_ispu = valid_merge[ISPU_FEATURES]\n",
    "y_ispu = valid_merge[\"target\"]\n",
    "\n",
    "dtrain = lgb.Dataset(X_ispu, label=y_ispu)\n",
    "\n",
    "ispu_model = lgb.train(\n",
    "    {\n",
    "        \"objective\": \"multiclass\",\n",
    "        \"num_class\": 3,\n",
    "        \"learning_rate\": 0.05,\n",
    "        \"num_leaves\": 63,\n",
    "        \"verbosity\": -1,\n",
    "        \"seed\": 42,\n",
    "    },\n",
    "    dtrain,\n",
    "    num_boost_round=300\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1976022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold: [0.2, 0.2, 0.2]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "probs = ispu_model.predict(X_ispu)\n",
    "best_t = [0.33, 0.33, 0.33]\n",
    "\n",
    "for c in range(3):\n",
    "    best_f1 = 0\n",
    "    for t in np.linspace(0.2, 0.6, 25):\n",
    "        pred = probs.argmax(1)\n",
    "        pred[probs[:, c] > t] = c\n",
    "        f1 = f1_score(y_ispu, pred, average=\"macro\")\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_t[c] = t\n",
    "\n",
    "print(\"Best threshold:\", best_t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1a12ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv(\"sample_submission.csv\")\n",
    "\n",
    "sub[\"tanggal\"] = pd.to_datetime(sub[\"id\"].str.split(\"_\").str[0])\n",
    "sub[\"lokasi_clean\"] = sub[\"id\"].str.split(\"_\").str[1]\n",
    "sub = sub.sort_values([\"lokasi_clean\", \"tanggal\"]).reset_index(drop=True)\n",
    "\n",
    "sub[\"lokasi_enc\"] = le_loc.transform(sub[\"lokasi_clean\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56375d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "sub = pd.read_csv(\"sample_submission.csv\")\n",
    "\n",
    "sub[\"tanggal\"] = pd.to_datetime(sub[\"id\"].str.split(\"_\").str[0])\n",
    "sub[\"lokasi_clean\"] = sub[\"id\"].str.split(\"_\").str[1]\n",
    "\n",
    "sub = sub.sort_values([\"lokasi_clean\", \"tanggal\"]).reset_index(drop=True)\n",
    "\n",
    "# encode lokasi (PASTI sama dengan df_model)\n",
    "sub[\"lokasi_enc\"] = le_loc.transform(sub[\"lokasi_clean\"])\n",
    "\n",
    "# tanggal terakhir di data training per lokasi\n",
    "last_dates = (\n",
    "    df_model.groupby(\"lokasi_clean\")[\"tanggal\"]\n",
    "    .max()\n",
    "    .to_dict()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "49c60dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_rows = []\n",
    "\n",
    "for loc in sub[\"lokasi_clean\"].unique():\n",
    "\n",
    "    hist = (\n",
    "        df_model[df_model[\"lokasi_clean\"] == loc]\n",
    "        .sort_values(\"tanggal\")\n",
    "        .iloc[-3:][POLLUTANT_COLS]\n",
    "        .values.tolist()\n",
    "    )\n",
    "\n",
    "    future_rows = sub[sub[\"lokasi_clean\"] == loc].sort_values(\"tanggal\")\n",
    "\n",
    "    for _, row in future_rows.iterrows():\n",
    "\n",
    "        tgl = row[\"tanggal\"]\n",
    "\n",
    "        feat = {\n",
    "            \"month\": tgl.month,\n",
    "            \"dayofyear\": tgl.dayofyear,\n",
    "            \"dayofweek\": tgl.dayofweek,\n",
    "            \"lokasi_enc\": row[\"lokasi_enc\"],\n",
    "        }\n",
    "\n",
    "        for i, col in enumerate(POLLUTANT_COLS):\n",
    "            feat[f\"{col}_lag1\"] = hist[-1][i]\n",
    "            feat[f\"{col}_lag2\"] = hist[-2][i]\n",
    "            feat[f\"{col}_lag3\"] = hist[-3][i]\n",
    "\n",
    "        Xf = pd.DataFrame([feat])\n",
    "\n",
    "        new_vals = []\n",
    "        preds_pol = {}\n",
    "\n",
    "        for col in POLLUTANT_COLS:\n",
    "            pred = pollutant_models[col].predict(Xf)[0]\n",
    "            new_vals.append(pred)\n",
    "            preds_pol[col] = pred\n",
    "\n",
    "        hist.append(new_vals)\n",
    "        hist.pop(0)\n",
    "\n",
    "        # ambil cuaca terakhir dari training\n",
    "        last_weather = (\n",
    "            df_model[df_model[\"lokasi_clean\"] == loc]\n",
    "            .sort_values(\"tanggal\")\n",
    "            .iloc[-1][WEATHER_COLS]\n",
    "        )\n",
    "\n",
    "        for col in WEATHER_COLS:\n",
    "            feat[col] = last_weather[col]\n",
    "\n",
    "        feat.update(preds_pol)\n",
    "        feat[\"id\"] = row[\"id\"]\n",
    "        feat[\"lokasi_clean\"] = loc\n",
    "        feat[\"tanggal\"] = tgl\n",
    "\n",
    "\n",
    "        forecast_rows.append(feat)\n",
    "\n",
    "df_future = pd.DataFrame(forecast_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca3b682f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for loc in sub[\"lokasi_clean\"].unique():\n",
    "\n",
    "    # ambil baris masa depan khusus lokasi ini\n",
    "    loc_rows = (\n",
    "        df_future[df_future[\"lokasi_clean\"] == loc]\n",
    "        .sort_values(\"tanggal\")\n",
    "    )\n",
    "\n",
    "    # history target terakhir (7 hari)\n",
    "    last_targets = (\n",
    "        df_model[df_model[\"lokasi_clean\"] == loc]\n",
    "        .sort_values(\"tanggal\")[\"target\"]\n",
    "        .iloc[-7:]\n",
    "        .tolist()\n",
    "    )\n",
    "\n",
    "    for _, row in loc_rows.iterrows():\n",
    "\n",
    "        # ===== fitur ISPU =====\n",
    "        feat_ispu = {col: row[col] for col in POLLUTANT_COLS}\n",
    "\n",
    "        # tambah cuaca\n",
    "        for col in WEATHER_COLS:\n",
    "            feat_ispu[col] = row.get(col, np.nan)\n",
    "\n",
    "        # tambah waktu + lag target\n",
    "        feat_ispu.update({\n",
    "            \"month\": row[\"month\"],\n",
    "            \"dayofyear\": row[\"dayofyear\"],\n",
    "            \"dayofweek\": row[\"dayofweek\"],\n",
    "            \"lokasi_enc\": row[\"lokasi_enc\"],\n",
    "            \"target_lag1\": last_targets[-1],\n",
    "            \"target_lag2\": last_targets[-2],\n",
    "            \"target_roll7\": np.mean(last_targets[-7:])\n",
    "        })\n",
    "\n",
    "        Xi = pd.DataFrame([feat_ispu])\n",
    "\n",
    "        # ===== prediksi =====\n",
    "        prob = ispu_model.predict(Xi)\n",
    "        pred = prob.argmax(1)\n",
    "\n",
    "        for c, t in enumerate(best_t):\n",
    "            pred[prob[:, c] > t] = c\n",
    "\n",
    "        pred_val = int(pred[0])\n",
    "        results.append(pred_val)\n",
    "\n",
    "        # ===== update history autoregressive =====\n",
    "        last_targets.append(pred_val)\n",
    "        last_targets.pop(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f760975",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1496ec52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ submission_step5.csv siap upload\n"
     ]
    }
   ],
   "source": [
    "INV_LABEL_MAP = {0: \"BAIK\", 1: \"SEDANG\", 2: \"TIDAK SEHAT\"}\n",
    "\n",
    "sub_final = pd.read_csv(\"sample_submission.csv\")\n",
    "\n",
    "pred_df = df_future[[\"id\"]].copy()\n",
    "pred_df[\"kategori\"] = [INV_LABEL_MAP[i] for i in results]\n",
    "\n",
    "\n",
    "sub_final = sub_final.merge(pred_df, on=\"id\", how=\"left\")\n",
    "\n",
    "sub_final.to_csv(\"submission_step_5.csv\", index=False)\n",
    "\n",
    "print(\"✅ submission_step5.csv siap upload\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c6415659",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"submission_step_5.csv\", sep=\";\")  \n",
    "df.to_csv(\"submission_step_5.csv\", index=False)     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1054af04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
