{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "701632a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "PATH = Path(\"merged_libur_cuaca_ispu_ndvi.csv\")\n",
    "\n",
    "df = pd.read_csv(PATH, sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ebc3927d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_15968\\3085690969.py:24: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.groupby(\"lokasi_clean\", group_keys=False).apply(reindex_daily)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tanggal</th>\n",
       "      <th>periode_data</th>\n",
       "      <th>pm_sepuluh</th>\n",
       "      <th>pm_duakomalima</th>\n",
       "      <th>sulfur_dioksida</th>\n",
       "      <th>karbon_monoksida</th>\n",
       "      <th>ozon</th>\n",
       "      <th>nitrogen_dioksida</th>\n",
       "      <th>kategori</th>\n",
       "      <th>temperature_2m_max (°C)</th>\n",
       "      <th>...</th>\n",
       "      <th>pm25_missing</th>\n",
       "      <th>month</th>\n",
       "      <th>dayofyear</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>month_sin</th>\n",
       "      <th>month_cos</th>\n",
       "      <th>doy_sin</th>\n",
       "      <th>doy_cos</th>\n",
       "      <th>dow_sin</th>\n",
       "      <th>dow_cos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>201001.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>SEDANG</td>\n",
       "      <td>29.4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.017213</td>\n",
       "      <td>0.999852</td>\n",
       "      <td>-0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-01-02</td>\n",
       "      <td>201001.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>BAIK</td>\n",
       "      <td>30.8</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.034422</td>\n",
       "      <td>0.999407</td>\n",
       "      <td>-0.974928</td>\n",
       "      <td>-0.222521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-01-03</td>\n",
       "      <td>201001.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>BAIK</td>\n",
       "      <td>30.4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.051620</td>\n",
       "      <td>0.998667</td>\n",
       "      <td>-0.781831</td>\n",
       "      <td>0.623490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>201001.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>BAIK</td>\n",
       "      <td>30.3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.068802</td>\n",
       "      <td>0.997630</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-01-05</td>\n",
       "      <td>201001.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>BAIK</td>\n",
       "      <td>29.9</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.085965</td>\n",
       "      <td>0.996298</td>\n",
       "      <td>0.781831</td>\n",
       "      <td>0.623490</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     tanggal  periode_data  pm_sepuluh  pm_duakomalima  sulfur_dioksida  \\\n",
       "0 2010-01-01      201001.0        60.0            73.0              4.0   \n",
       "1 2010-01-02      201001.0        32.0            73.0              2.0   \n",
       "2 2010-01-03      201001.0        27.0            73.0              2.0   \n",
       "3 2010-01-04      201001.0        22.0            73.0              2.0   \n",
       "4 2010-01-05      201001.0        25.0            73.0              2.0   \n",
       "\n",
       "   karbon_monoksida  ozon  nitrogen_dioksida kategori  \\\n",
       "0              73.0  27.0               14.0   SEDANG   \n",
       "1              16.0  33.0                9.0     BAIK   \n",
       "2              19.0  20.0                9.0     BAIK   \n",
       "3              16.0  15.0                6.0     BAIK   \n",
       "4              17.0  15.0                8.0     BAIK   \n",
       "\n",
       "   temperature_2m_max (°C)  ...  pm25_missing  month  dayofyear  dayofweek  \\\n",
       "0                     29.4  ...             1      1          1          4   \n",
       "1                     30.8  ...             1      1          2          5   \n",
       "2                     30.4  ...             1      1          3          6   \n",
       "3                     30.3  ...             1      1          4          0   \n",
       "4                     29.9  ...             1      1          5          1   \n",
       "\n",
       "   month_sin  month_cos   doy_sin   doy_cos   dow_sin   dow_cos  \n",
       "0        0.5   0.866025  0.017213  0.999852 -0.433884 -0.900969  \n",
       "1        0.5   0.866025  0.034422  0.999407 -0.974928 -0.222521  \n",
       "2        0.5   0.866025  0.051620  0.998667 -0.781831  0.623490  \n",
       "3        0.5   0.866025  0.068802  0.997630  0.000000  1.000000  \n",
       "4        0.5   0.866025  0.085965  0.996298  0.781831  0.623490  \n",
       "\n",
       "[5 rows x 46 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parse tanggal\n",
    "df[\"tanggal\"] = pd.to_datetime(df[\"tanggal\"], dayfirst=True)\n",
    "\n",
    "# sort\n",
    "df = df.sort_values([\"lokasi_clean\", \"tanggal\"]).reset_index(drop=True)\n",
    "\n",
    "# drop kolom\n",
    "DROP_COLS = [\"max\", \"parameter_pencemar_kritis\", \"time\", \"id\", \"stasiun\"]\n",
    "df = df.drop(columns=DROP_COLS, errors=\"ignore\")\n",
    "\n",
    "# label mapping\n",
    "LABEL_MAP = {\"BAIK\": 0, \"SEDANG\": 1, \"TIDAK SEHAT\": 2}\n",
    "df = df[df[\"kategori\"].notna()].copy()\n",
    "df[\"target\"] = df[\"kategori\"].map(LABEL_MAP).astype(int)\n",
    "\n",
    "\n",
    "# REINDEX \n",
    "def reindex_daily(g):\n",
    "    idx = pd.date_range(g[\"tanggal\"].min(), g[\"tanggal\"].max(), freq=\"D\")\n",
    "    g = g.set_index(\"tanggal\").reindex(idx)\n",
    "    g[\"lokasi_clean\"] = g[\"lokasi_clean\"].iloc[0]\n",
    "    return g.reset_index().rename(columns={\"index\": \"tanggal\"})\n",
    "\n",
    "df = df.groupby(\"lokasi_clean\", group_keys=False).apply(reindex_daily)\n",
    "\n",
    "\n",
    "# PM2.5 HANDLING\n",
    "df[\"pm25_missing\"] = df[\"pm_duakomalima\"].isna().astype(int)\n",
    "\n",
    "median_pm25 = (\n",
    "    df[df[\"tanggal\"] >= \"2021-01-01\"]\n",
    "    .groupby(\"lokasi_clean\")[\"pm_duakomalima\"]\n",
    "    .median()\n",
    ")\n",
    "\n",
    "df[\"pm_duakomalima\"] = df[\"pm_duakomalima\"].fillna(\n",
    "    df[\"lokasi_clean\"].map(median_pm25)\n",
    ")\n",
    "\n",
    "\n",
    "# buang baris tanpa target (penting untuk training)\n",
    "df = df[df[\"target\"].notna()].copy()\n",
    "\n",
    "\n",
    "# TIME FEATURES \n",
    "df[\"month\"] = df[\"tanggal\"].dt.month\n",
    "df[\"dayofyear\"] = df[\"tanggal\"].dt.dayofyear\n",
    "df[\"dayofweek\"] = df[\"tanggal\"].dt.dayofweek\n",
    "\n",
    "df[\"month_sin\"] = np.sin(2*np.pi*df[\"month\"]/12)\n",
    "df[\"month_cos\"] = np.cos(2*np.pi*df[\"month\"]/12)\n",
    "\n",
    "df[\"doy_sin\"] = np.sin(2*np.pi*df[\"dayofyear\"]/365)\n",
    "df[\"doy_cos\"] = np.cos(2*np.pi*df[\"dayofyear\"]/365)\n",
    "\n",
    "df[\"dow_sin\"] = np.sin(2*np.pi*df[\"dayofweek\"]/7)\n",
    "df[\"dow_cos\"] = np.cos(2*np.pi*df[\"dayofweek\"]/7)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3acff62a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_15968\\172493383.py:42: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.groupby(\"lokasi_clean\", group_keys=False).apply(create_temporal_features)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_15968\\172493383.py:46: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_isnan\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_15968\\172493383.py:46: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_isnan\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_15968\\172493383.py:46: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_isnan\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_15968\\172493383.py:46: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_isnan\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_15968\\172493383.py:46: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_isnan\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_15968\\172493383.py:46: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_isnan\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_15968\\172493383.py:46: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_isnan\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_15968\\172493383.py:46: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_isnan\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_15968\\172493383.py:46: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_isnan\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_15968\\172493383.py:46: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_isnan\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_15968\\172493383.py:46: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_isnan\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_15968\\172493383.py:46: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_isnan\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_15968\\172493383.py:46: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_isnan\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_15968\\172493383.py:46: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_isnan\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_15968\\172493383.py:46: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_isnan\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_15968\\172493383.py:46: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_isnan\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_15968\\172493383.py:46: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_isnan\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_15968\\172493383.py:46: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_isnan\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_15968\\172493383.py:46: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_isnan\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_15968\\172493383.py:46: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_isnan\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_15968\\172493383.py:46: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_isnan\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_15968\\172493383.py:46: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_isnan\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_15968\\172493383.py:46: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_isnan\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_15968\\172493383.py:46: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_isnan\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_15968\\172493383.py:46: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_isnan\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_15968\\172493383.py:46: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_isnan\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_15968\\172493383.py:46: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_isnan\"] = df[col].isna().astype(int)\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_15968\\172493383.py:46: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_isnan\"] = df[col].isna().astype(int)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tanggal</th>\n",
       "      <th>periode_data</th>\n",
       "      <th>pm_sepuluh</th>\n",
       "      <th>pm_duakomalima</th>\n",
       "      <th>sulfur_dioksida</th>\n",
       "      <th>karbon_monoksida</th>\n",
       "      <th>ozon</th>\n",
       "      <th>nitrogen_dioksida</th>\n",
       "      <th>kategori</th>\n",
       "      <th>temperature_2m_max (°C)</th>\n",
       "      <th>...</th>\n",
       "      <th>nitrogen_dioksida_roll_mean_7_isnan</th>\n",
       "      <th>nitrogen_dioksida_roll_std_7_isnan</th>\n",
       "      <th>sulfur_dioksida_roll_mean_3_isnan</th>\n",
       "      <th>sulfur_dioksida_roll_std_3_isnan</th>\n",
       "      <th>sulfur_dioksida_roll_mean_7_isnan</th>\n",
       "      <th>sulfur_dioksida_roll_std_7_isnan</th>\n",
       "      <th>karbon_monoksida_roll_mean_3_isnan</th>\n",
       "      <th>karbon_monoksida_roll_std_3_isnan</th>\n",
       "      <th>karbon_monoksida_roll_mean_7_isnan</th>\n",
       "      <th>karbon_monoksida_roll_std_7_isnan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>201001.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>SEDANG</td>\n",
       "      <td>29.4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-01-02</td>\n",
       "      <td>201001.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>BAIK</td>\n",
       "      <td>30.8</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-01-03</td>\n",
       "      <td>201001.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>BAIK</td>\n",
       "      <td>30.4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>201001.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>BAIK</td>\n",
       "      <td>30.3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-01-05</td>\n",
       "      <td>201001.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>BAIK</td>\n",
       "      <td>29.9</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 166 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     tanggal  periode_data  pm_sepuluh  pm_duakomalima  sulfur_dioksida  \\\n",
       "0 2010-01-01      201001.0        60.0            73.0              4.0   \n",
       "1 2010-01-02      201001.0        32.0            73.0              2.0   \n",
       "2 2010-01-03      201001.0        27.0            73.0              2.0   \n",
       "3 2010-01-04      201001.0        22.0            73.0              2.0   \n",
       "4 2010-01-05      201001.0        25.0            73.0              2.0   \n",
       "\n",
       "   karbon_monoksida  ozon  nitrogen_dioksida kategori  \\\n",
       "0              73.0  27.0               14.0   SEDANG   \n",
       "1              16.0  33.0                9.0     BAIK   \n",
       "2              19.0  20.0                9.0     BAIK   \n",
       "3              16.0  15.0                6.0     BAIK   \n",
       "4              17.0  15.0                8.0     BAIK   \n",
       "\n",
       "   temperature_2m_max (°C)  ...  nitrogen_dioksida_roll_mean_7_isnan  \\\n",
       "0                     29.4  ...                                    1   \n",
       "1                     30.8  ...                                    1   \n",
       "2                     30.4  ...                                    1   \n",
       "3                     30.3  ...                                    1   \n",
       "4                     29.9  ...                                    1   \n",
       "\n",
       "   nitrogen_dioksida_roll_std_7_isnan  sulfur_dioksida_roll_mean_3_isnan  \\\n",
       "0                                   1                                  1   \n",
       "1                                   1                                  1   \n",
       "2                                   1                                  1   \n",
       "3                                   1                                  0   \n",
       "4                                   1                                  0   \n",
       "\n",
       "   sulfur_dioksida_roll_std_3_isnan  sulfur_dioksida_roll_mean_7_isnan  \\\n",
       "0                                 1                                  1   \n",
       "1                                 1                                  1   \n",
       "2                                 1                                  1   \n",
       "3                                 0                                  1   \n",
       "4                                 0                                  1   \n",
       "\n",
       "   sulfur_dioksida_roll_std_7_isnan  karbon_monoksida_roll_mean_3_isnan  \\\n",
       "0                                 1                                   1   \n",
       "1                                 1                                   1   \n",
       "2                                 1                                   1   \n",
       "3                                 1                                   0   \n",
       "4                                 1                                   0   \n",
       "\n",
       "   karbon_monoksida_roll_std_3_isnan  karbon_monoksida_roll_mean_7_isnan  \\\n",
       "0                                  1                                   1   \n",
       "1                                  1                                   1   \n",
       "2                                  1                                   1   \n",
       "3                                  0                                   1   \n",
       "4                                  0                                   1   \n",
       "\n",
       "   karbon_monoksida_roll_std_7_isnan  \n",
       "0                                  1  \n",
       "1                                  1  \n",
       "2                                  1  \n",
       "3                                  1  \n",
       "4                                  1  \n",
       "\n",
       "[5 rows x 166 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitur lag dan rolling\n",
    "\n",
    "POLLUTANT_COLS = [\n",
    "    \"pm_sepuluh\",\n",
    "    \"pm_duakomalima\",\n",
    "    \"ozon\",\n",
    "    \"nitrogen_dioksida\",\n",
    "    \"sulfur_dioksida\",\n",
    "    \"karbon_monoksida\",\n",
    "]\n",
    "\n",
    "WEATHER_COLS = [\n",
    "    \"temperature_2m_mean (°C)\",\n",
    "    \"relative_humidity_2m_mean (%)\",\n",
    "    \"wind_speed_10m_mean (km/h)\",\n",
    "    \"precipitation_sum (mm)\",\n",
    "    \"cloud_cover_mean (%)\",\n",
    "    \"surface_pressure_mean (hPa)\",\n",
    "]\n",
    "\n",
    "LAG_FEATURES = POLLUTANT_COLS + WEATHER_COLS\n",
    "\n",
    "LAGS = [1, 2, 3]\n",
    "ROLL_WINDOWS = [3, 7]\n",
    "def create_temporal_features(g):\n",
    "    g = g.sort_values(\"tanggal\")\n",
    "\n",
    "    # ===== LAG untuk POLUTAN + CUACA =====\n",
    "    for col in POLLUTANT_COLS + WEATHER_COLS:\n",
    "        for lag in LAGS:\n",
    "            g[f\"{col}_lag_{lag}\"] = g[col].shift(lag)\n",
    "\n",
    "    # ===== ROLLING hanya untuk polutan =====\n",
    "    for col in POLLUTANT_COLS:\n",
    "        for w in ROLL_WINDOWS:\n",
    "            g[f\"{col}_roll_mean_{w}\"] = g[col].shift(1).rolling(w).mean()\n",
    "            g[f\"{col}_roll_std_{w}\"]  = g[col].shift(1).rolling(w).std()\n",
    "\n",
    "    return g\n",
    "\n",
    "\n",
    "df = df.groupby(\"lokasi_clean\", group_keys=False).apply(create_temporal_features)\n",
    "lag_cols = [c for c in df.columns if \"lag_\" in c or \"roll_\" in c]\n",
    "\n",
    "for col in lag_cols:\n",
    "    df[f\"{col}_isnan\"] = df[col].isna().astype(int)\n",
    "\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5b7f9681",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "df_model = df.dropna(subset=[\"target\"]).reset_index(drop=True)\n",
    "\n",
    "H = 30\n",
    "\n",
    "rows = []\n",
    "\n",
    "for loc, g in df_model.groupby(\"lokasi_clean\"):\n",
    "    g = g.sort_values(\"tanggal\").reset_index(drop=True)\n",
    "\n",
    "    # precompute lag POLUTAN + CUACA\n",
    "    for col in POLLUTANT_COLS + WEATHER_COLS:\n",
    "        g[f\"{col}_lag_1\"] = g[col].shift(0)\n",
    "        g[f\"{col}_lag_2\"] = g[col].shift(1)\n",
    "        g[f\"{col}_lag_3\"] = g[col].shift(2)\n",
    "\n",
    "    for h in range(1, H + 1):\n",
    "        g_future = g.shift(-h)\n",
    "\n",
    "        temp = pd.DataFrame({\n",
    "            \"lokasi_clean\": loc,\n",
    "            \"tanggal\": g[\"tanggal\"],\n",
    "            \"horizon\": h,\n",
    "            \"month\": g[\"tanggal\"].dt.month,\n",
    "            \"dayofyear\": g[\"tanggal\"].dt.dayofyear,\n",
    "            \"dayofweek\": g[\"tanggal\"].dt.dayofweek,\n",
    "        })\n",
    "\n",
    "        # fitur lag\n",
    "        for col in POLLUTANT_COLS + WEATHER_COLS:\n",
    "            temp[f\"{col}_lag_1\"] = g[f\"{col}_lag_1\"]\n",
    "            temp[f\"{col}_lag_2\"] = g[f\"{col}_lag_2\"]\n",
    "            temp[f\"{col}_lag_3\"] = g[f\"{col}_lag_3\"]\n",
    "\n",
    "        # target masa depan\n",
    "        for col in POLLUTANT_COLS:\n",
    "            temp[f\"target_{col}\"] = g_future[col]\n",
    "\n",
    "        rows.append(temp)\n",
    "\n",
    "df_forecast = pd.concat(rows, ignore_index=True).dropna().reset_index(drop=True)\n",
    "\n",
    "\n",
    "le_loc = LabelEncoder()\n",
    "\n",
    "# FIT dari data training asli\n",
    "df_model[\"lokasi_enc\"] = le_loc.fit_transform(df_model[\"lokasi_clean\"])\n",
    "\n",
    "# BARU transform ke df_forecast\n",
    "df_forecast[\"lokasi_enc\"] = le_loc.transform(df_forecast[\"lokasi_clean\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "11bf470a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "pollutant_models = {}\n",
    "\n",
    "FEATURES_F = (\n",
    "    [f\"{col}_lag_{l}\" for col in POLLUTANT_COLS for l in LAGS] +\n",
    "    [f\"{col}_lag_{l}\" for col in WEATHER_COLS for l in LAGS] +\n",
    "    [\"month\", \"dayofyear\", \"dayofweek\", \"lokasi_enc\", \"horizon\"]\n",
    ")\n",
    "\n",
    "\n",
    "for col in POLLUTANT_COLS:\n",
    "\n",
    "    y_col = f\"target_{col}\"\n",
    "\n",
    "    Xf = df_forecast[FEATURES_F]\n",
    "    yf = df_forecast[y_col]\n",
    "\n",
    "    train_data = lgb.Dataset(Xf, label=yf)\n",
    "\n",
    "    params = {\n",
    "        \"objective\": \"regression\",\n",
    "        \"metric\": \"l2\",\n",
    "        \"learning_rate\": 0.05,\n",
    "        \"num_leaves\": 64,\n",
    "        \"verbosity\": -1,\n",
    "        \"seed\": 42,\n",
    "    }\n",
    "\n",
    "    model = lgb.train(params, train_data, num_boost_round=500)\n",
    "    pollutant_models[col] = model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5142136a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# TIME SERIES CV UNTUK OOF FORECAST POLUTAN\n",
    "# ============================================\n",
    "\n",
    "SPLITS = [\"2022-01-01\", \"2023-01-01\", \"2024-01-01\"]\n",
    "\n",
    "oof_parts = []\n",
    "\n",
    "for split_date in SPLITS:\n",
    "\n",
    "    train_df = df_model[df_model[\"tanggal\"] < split_date].copy()\n",
    "    valid_df = df_model[df_model[\"tanggal\"] >= split_date].copy()\n",
    "\n",
    "    fold_rows = []\n",
    "\n",
    "    for loc in valid_df[\"lokasi_clean\"].unique():\n",
    "\n",
    "        hist = (\n",
    "            train_df[train_df[\"lokasi_clean\"] == loc]\n",
    "            .sort_values(\"tanggal\")\n",
    "            .iloc[-3:][POLLUTANT_COLS]\n",
    "            .values.tolist()\n",
    "        )\n",
    "\n",
    "        weather_hist = (\n",
    "            train_df[train_df[\"lokasi_clean\"] == loc]\n",
    "            .sort_values(\"tanggal\")\n",
    "            .iloc[-7:][WEATHER_COLS]\n",
    "        )\n",
    "        weather_future = weather_hist.mean().values\n",
    "\n",
    "        future_rows = valid_df[valid_df[\"lokasi_clean\"] == loc].sort_values(\"tanggal\")\n",
    "\n",
    "        last_date = train_df[train_df[\"lokasi_clean\"] == loc][\"tanggal\"].max()\n",
    "\n",
    "        for _, row in future_rows.iterrows():\n",
    "\n",
    "            horizon = (row[\"tanggal\"] - last_date).days\n",
    "\n",
    "            feat = {\n",
    "                \"horizon\": horizon,\n",
    "                \"month\": row[\"month\"],\n",
    "                \"dayofyear\": row[\"dayofyear\"],\n",
    "                \"dayofweek\": row[\"dayofweek\"],\n",
    "                \"lokasi_enc\": le_loc.transform([loc])[0],\n",
    "            }\n",
    "\n",
    "            for i, col in enumerate(POLLUTANT_COLS):\n",
    "                feat[f\"{col}_lag_1\"] = hist[-1][i]\n",
    "                feat[f\"{col}_lag_2\"] = hist[-2][i]\n",
    "                feat[f\"{col}_lag_3\"] = hist[-3][i]\n",
    "\n",
    "            for i, col in enumerate(WEATHER_COLS):\n",
    "                feat[f\"{col}_lag_1\"] = weather_future[i]\n",
    "                feat[f\"{col}_lag_2\"] = weather_future[i]\n",
    "                feat[f\"{col}_lag_3\"] = weather_future[i]\n",
    "\n",
    "            Xf = pd.DataFrame([feat])\n",
    "\n",
    "            preds = []\n",
    "            for col in POLLUTANT_COLS:\n",
    "                p = pollutant_models[col].predict(Xf)[0]\n",
    "                preds.append(p)\n",
    "\n",
    "            hist.append(preds)\n",
    "            hist.pop(0)\n",
    "\n",
    "            row_out = row.copy()\n",
    "            for i, col in enumerate(POLLUTANT_COLS):\n",
    "                row_out[col] = preds[i]\n",
    "\n",
    "            fold_rows.append(row_out)\n",
    "\n",
    "    oof_parts.append(pd.DataFrame(fold_rows))\n",
    "\n",
    "df_oof = pd.concat(oof_parts).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "27265407",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_oof[\"lokasi_enc\"] = le_loc.transform(df_oof[\"lokasi_clean\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "810c6816",
   "metadata": {},
   "outputs": [],
   "source": [
    "ISPU_PARAMS = {\n",
    "    \"objective\": \"multiclass\",\n",
    "    \"num_class\": 3,\n",
    "    \"metric\": \"None\",\n",
    "    \"learning_rate\": 0.03,\n",
    "    \"num_leaves\": 63,\n",
    "    \"min_data_in_leaf\": 30,\n",
    "    \"feature_fraction\": 0.9,\n",
    "    \"bagging_fraction\": 0.9,\n",
    "    \"bagging_freq\": 5,\n",
    "    \"verbosity\": -1,\n",
    "    \"seed\": 42,\n",
    "    \"class_weight\": \"balanced\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "39e0837f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_ispu_interactions(df):\n",
    "    df = df.copy()\n",
    "\n",
    "    df[\"pm_ratio\"] = df[\"pm_duakomalima\"] / (df[\"pm_sepuluh\"] + 1e-3)\n",
    "\n",
    "    df[\"gas_sum\"] = (\n",
    "        df[\"ozon\"] +\n",
    "        df[\"nitrogen_dioksida\"] +\n",
    "        df[\"sulfur_dioksida\"]\n",
    "    )\n",
    "\n",
    "    df[\"pm25_ozon\"] = df[\"pm_duakomalima\"] * df[\"ozon\"]\n",
    "    df[\"pm10_no2\"] = df[\"pm_sepuluh\"] * df[\"nitrogen_dioksida\"]\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2de08805",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================================\n",
    "# TRAIN ISPU DARI DISTRIBUSI OOF (WAJIB)\n",
    "# ============================================\n",
    "\n",
    "train_ispu_df = pd.concat([\n",
    "    df_model[df_model[\"tanggal\"] < \"2022-01-01\"],  # bagian awal asli\n",
    "    df_oof                                          # bagian forecast\n",
    "]).reset_index(drop=True)\n",
    "\n",
    "train_ispu_df = add_ispu_interactions(train_ispu_df)\n",
    "df_oof = add_ispu_interactions(df_oof)\n",
    "\n",
    "\n",
    "ISPU_FEATURES = [\n",
    "    *POLLUTANT_COLS,\n",
    "    \"pm_ratio\",\n",
    "    \"gas_sum\",\n",
    "    \"pm25_ozon\",\n",
    "    \"pm10_no2\",\n",
    "    \"month\", \"dayofyear\", \"dayofweek\", \"lokasi_enc\"\n",
    "]\n",
    "\n",
    "\n",
    "X_ispu = train_ispu_df[ISPU_FEATURES]\n",
    "y_ispu = train_ispu_df[\"target\"]\n",
    "\n",
    "train_data = lgb.Dataset(X_ispu, label=y_ispu)\n",
    "\n",
    "ispu_model = lgb.train(ISPU_PARAMS, train_data, num_boost_round=700)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f1976022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold: [0.42457627118644065, 0.5110169491525424, 0.42457627118644065]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "\n",
    "X_val = df_oof[ISPU_FEATURES]\n",
    "y_val = df_oof[\"target\"]\n",
    "\n",
    "probs = ispu_model.predict(X_val)\n",
    "\n",
    "best_t = [0.33, 0.33, 0.33]\n",
    "\n",
    "for c in range(3):\n",
    "    best_score = 0\n",
    "    for t in np.linspace(0.05, 0.9, 60):\n",
    "\n",
    "        pred = probs.argmax(1).copy()\n",
    "        pred[probs[:, c] > t] = c\n",
    "\n",
    "        score = f1_score(y_val, pred, average=\"macro\")\n",
    "\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_t[c] = t\n",
    "\n",
    "\n",
    "print(\"Best threshold:\", best_t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c1a12ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv(\"sample_submission.csv\")\n",
    "\n",
    "sub[\"tanggal\"] = pd.to_datetime(sub[\"id\"].str.split(\"_\").str[0])\n",
    "sub[\"lokasi_clean\"] = sub[\"id\"].str.split(\"_\").str[1]\n",
    "sub = sub.sort_values([\"lokasi_clean\", \"tanggal\"]).reset_index(drop=True)\n",
    "\n",
    "sub[\"lokasi_enc\"] = le_loc.transform(sub[\"lokasi_clean\"])\n",
    "last_dates = (\n",
    "    df_model.groupby(\"lokasi_clean\")[\"tanggal\"].max().to_dict()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f766fe93",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_rows = []\n",
    "\n",
    "for loc in sub[\"lokasi_clean\"].unique():\n",
    "\n",
    "    # ===== riwayat 3 hari terakhir =====\n",
    "    hist = (\n",
    "        df_model[df_model[\"lokasi_clean\"] == loc]\n",
    "        .sort_values(\"tanggal\")\n",
    "        .iloc[-3:][POLLUTANT_COLS]\n",
    "        .values.tolist()\n",
    "    )\n",
    "    # ===== riwayat cuaca 7 hari terakhir → untuk proxy masa depan =====\n",
    "    weather_hist = (\n",
    "        df_model[df_model[\"lokasi_clean\"] == loc]\n",
    "        .sort_values(\"tanggal\")\n",
    "        .iloc[-7:][WEATHER_COLS]\n",
    "    )\n",
    "\n",
    "# pakai rata-rata sebagai cuaca masa depan (climatology cepat)\n",
    "    weather_future = weather_hist.mean().values\n",
    "\n",
    "\n",
    "    future_rows = (\n",
    "        sub[sub[\"lokasi_clean\"] == loc]\n",
    "        .sort_values(\"tanggal\")\n",
    "    )\n",
    "\n",
    "    for _, row in future_rows.iterrows():\n",
    "\n",
    "        tgl = row[\"tanggal\"]\n",
    "\n",
    "        # ===== fitur forecast =====\n",
    "        feat = {\n",
    "            \"horizon\": (row[\"tanggal\"] - last_dates[loc]).days,\n",
    "            \"month\": tgl.month,\n",
    "            \"dayofyear\": tgl.dayofyear,\n",
    "            \"dayofweek\": tgl.dayofweek,\n",
    "            \"lokasi_enc\": row[\"lokasi_enc\"],\n",
    "        }\n",
    "\n",
    "        # ===== lag dari history rolling =====\n",
    "        for i, col in enumerate(POLLUTANT_COLS):\n",
    "            feat[f\"{col}_lag_1\"] = hist[-1][i]\n",
    "            feat[f\"{col}_lag_2\"] = hist[-2][i]\n",
    "            feat[f\"{col}_lag_3\"] = hist[-3][i]\n",
    "            \n",
    "        for i, col in enumerate(WEATHER_COLS):\n",
    "            feat[f\"{col}_lag_1\"] = weather_future[i]\n",
    "            feat[f\"{col}_lag_2\"] = weather_future[i]\n",
    "            feat[f\"{col}_lag_3\"] = weather_future[i]\n",
    "\n",
    "        Xf = pd.DataFrame([feat])\n",
    "\n",
    "        # ===== lag CUACA (pakai nilai rata-rata masa depan) =====\n",
    "\n",
    "\n",
    "        # ===== prediksi semua polutan =====\n",
    "        new_vals = []\n",
    "        preds_pol = {}\n",
    "\n",
    "        for i, col in enumerate(POLLUTANT_COLS):\n",
    "            pred = pollutant_models[col].predict(Xf)[0]\n",
    "            new_vals.append(pred)\n",
    "            preds_pol[col] = pred\n",
    "\n",
    "        # ===== update history (rolling window) =====\n",
    "        hist.append(new_vals)\n",
    "        hist.pop(0)\n",
    "\n",
    "        # ===== simpan =====\n",
    "        feat.update(preds_pol)\n",
    "        feat[\"id\"] = row[\"id\"]\n",
    "\n",
    "        forecast_rows.append(feat)\n",
    "\n",
    "df_future = pd.DataFrame(forecast_rows)\n",
    "df_future = add_ispu_interactions(df_future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "56375d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "sub = pd.read_csv(\"sample_submission.csv\")\n",
    "\n",
    "sub[\"tanggal\"] = pd.to_datetime(sub[\"id\"].str.split(\"_\").str[0])\n",
    "sub[\"lokasi_clean\"] = sub[\"id\"].str.split(\"_\").str[1]\n",
    "\n",
    "sub = sub.sort_values([\"lokasi_clean\", \"tanggal\"]).reset_index(drop=True)\n",
    "\n",
    "# encode lokasi (PASTI sama dengan df_model)\n",
    "sub[\"lokasi_enc\"] = le_loc.transform(sub[\"lokasi_clean\"])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ca3b682f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for _, row in df_future.iterrows():\n",
    "\n",
    "    feat_ispu = {col: row[col] for col in POLLUTANT_COLS}\n",
    "\n",
    "    feat_ispu[\"pm_ratio\"] = row[\"pm_duakomalima\"] / (row[\"pm_sepuluh\"] + 1e-3)\n",
    "    feat_ispu[\"gas_sum\"] = row[\"ozon\"] + row[\"nitrogen_dioksida\"] + row[\"sulfur_dioksida\"]\n",
    "    feat_ispu[\"pm25_ozon\"] = row[\"pm_duakomalima\"] * row[\"ozon\"]\n",
    "    feat_ispu[\"pm10_no2\"] = row[\"pm_sepuluh\"] * row[\"nitrogen_dioksida\"]\n",
    "\n",
    "\n",
    "    feat_ispu.update({\n",
    "        \"month\": row[\"month\"],\n",
    "        \"dayofyear\": row[\"dayofyear\"],\n",
    "        \"dayofweek\": row[\"dayofweek\"],\n",
    "        \"lokasi_enc\": row[\"lokasi_enc\"],   \n",
    "    })\n",
    "\n",
    "    Xi = pd.DataFrame([feat_ispu])\n",
    "\n",
    "    prob = ispu_model.predict(Xi)\n",
    "    pred = prob.argmax(1)\n",
    "\n",
    "    for c, t in enumerate(best_t):\n",
    "        pred[prob[:, c] > t] = c\n",
    "\n",
    "    results.append(int(pred[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1496ec52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ submission_step6.csv siap upload\n"
     ]
    }
   ],
   "source": [
    "INV_LABEL_MAP = {0: \"BAIK\", 1: \"SEDANG\", 2: \"TIDAK SEHAT\"}\n",
    "\n",
    "sub_final = pd.read_csv(\"sample_submission.csv\")\n",
    "\n",
    "pred_df = df_future[[\"id\"]].copy()\n",
    "pred_df[\"kategori\"] = [INV_LABEL_MAP[i] for i in results]\n",
    "\n",
    "\n",
    "sub_final = sub_final.merge(pred_df, on=\"id\", how=\"left\")\n",
    "\n",
    "sub_final.to_csv(\"submission_step6.csv\", index=False)\n",
    "\n",
    "print(\"✅ submission_step6.csv siap upload\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c6415659",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"submission_step6.csv\", sep=\";\")  \n",
    "df.to_csv(\"submission_step_6.csv\", index=False)     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9f805841",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pm_sepuluh</th>\n",
       "      <th>pm_duakomalima</th>\n",
       "      <th>ozon</th>\n",
       "      <th>nitrogen_dioksida</th>\n",
       "      <th>sulfur_dioksida</th>\n",
       "      <th>karbon_monoksida</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>455.000000</td>\n",
       "      <td>455.000000</td>\n",
       "      <td>455.000000</td>\n",
       "      <td>455.000000</td>\n",
       "      <td>455.000000</td>\n",
       "      <td>455.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>46.488784</td>\n",
       "      <td>47.334042</td>\n",
       "      <td>64.271536</td>\n",
       "      <td>28.547160</td>\n",
       "      <td>17.273770</td>\n",
       "      <td>23.783079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>11.056087</td>\n",
       "      <td>4.098559</td>\n",
       "      <td>6.628635</td>\n",
       "      <td>3.269486</td>\n",
       "      <td>3.271835</td>\n",
       "      <td>1.646593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>30.975903</td>\n",
       "      <td>39.458680</td>\n",
       "      <td>34.718069</td>\n",
       "      <td>22.162419</td>\n",
       "      <td>9.486155</td>\n",
       "      <td>15.448885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>37.566295</td>\n",
       "      <td>44.617876</td>\n",
       "      <td>59.233533</td>\n",
       "      <td>26.307729</td>\n",
       "      <td>15.674436</td>\n",
       "      <td>22.674737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>43.637282</td>\n",
       "      <td>47.397322</td>\n",
       "      <td>64.830733</td>\n",
       "      <td>27.784053</td>\n",
       "      <td>16.627110</td>\n",
       "      <td>23.978223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>56.628306</td>\n",
       "      <td>49.806336</td>\n",
       "      <td>69.266844</td>\n",
       "      <td>29.608150</td>\n",
       "      <td>17.935507</td>\n",
       "      <td>24.950018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>68.134252</td>\n",
       "      <td>61.750067</td>\n",
       "      <td>75.974955</td>\n",
       "      <td>38.520640</td>\n",
       "      <td>41.998066</td>\n",
       "      <td>28.192965</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       pm_sepuluh  pm_duakomalima        ozon  nitrogen_dioksida  \\\n",
       "count  455.000000      455.000000  455.000000         455.000000   \n",
       "mean    46.488784       47.334042   64.271536          28.547160   \n",
       "std     11.056087        4.098559    6.628635           3.269486   \n",
       "min     30.975903       39.458680   34.718069          22.162419   \n",
       "25%     37.566295       44.617876   59.233533          26.307729   \n",
       "50%     43.637282       47.397322   64.830733          27.784053   \n",
       "75%     56.628306       49.806336   69.266844          29.608150   \n",
       "max     68.134252       61.750067   75.974955          38.520640   \n",
       "\n",
       "       sulfur_dioksida  karbon_monoksida  \n",
       "count       455.000000        455.000000  \n",
       "mean         17.273770         23.783079  \n",
       "std           3.271835          1.646593  \n",
       "min           9.486155         15.448885  \n",
       "25%          15.674436         22.674737  \n",
       "50%          16.627110         23.978223  \n",
       "75%          17.935507         24.950018  \n",
       "max          41.998066         28.192965  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_future[POLLUTANT_COLS].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "94293929",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    452\n",
       "2      2\n",
       "0      1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(results).value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a4303b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
