{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ff1a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "\n",
    "NA_VALUES = [\"---\", \"--\", \"\", \" \", \"NA\", \"N/A\"]\n",
    "# =========================\n",
    "# FILE FINDER\n",
    "# =========================\n",
    "def find_file(name, start=Path.cwd()):\n",
    "    for ancestor in [start] + list(start.parents):\n",
    "        matches = list(ancestor.rglob(name))\n",
    "        if matches:\n",
    "            return matches[0]\n",
    "    return None\n",
    "\n",
    "\n",
    "def find_files(file_map):\n",
    "    found = {}\n",
    "    for key, filename in file_map.items():\n",
    "        path = find_file(filename)\n",
    "        if path:\n",
    "            found[key] = path\n",
    "        else:\n",
    "            print(f\"[WARNING] File not found: {filename}\")\n",
    "    return found\n",
    "\n",
    "eda_script_path = find_file(\"script_eda.py\")\n",
    "if eda_script_path is None:\n",
    "    raise FileNotFoundError(\"❌ script_eda.py tidak ditemukan di parent directory\")\n",
    "\n",
    "# tambahkan BASE PROJECT ke sys.path\n",
    "sys.path.append(str(eda_script_path.parent))\n",
    "\n",
    "# sekarang bisa import\n",
    "from script_eda import evaluate_dataset, extract_column_schema,find_internal_duplicate_columns,extract_single_schema,cek_value_data_column\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb6df06",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = find_file(\"merged_cuaca_ndvi_ispu.csv\")\n",
    "\n",
    "if path is None:\n",
    "    raise FileNotFoundError(\"❌ File merged tidak ditemukan\")\n",
    "\n",
    "df = pd.read_csv(path, na_values=NA_VALUES)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03727b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = \"kategori\"\n",
    "\n",
    "DROP_COLS = [\n",
    "    TARGET,\n",
    "    \"max\",\n",
    "    \"parameter_pencemar_kritis\",\n",
    "\n",
    "    # identifier / non-feature\n",
    "    \"id\",\n",
    "    \"tanggal\",\n",
    "    \"periode_data\",\n",
    "    \"time\",\n",
    "    \"stasiun\",\n",
    "    \"lokasi\",\n",
    "    \"lokasi_clean\",\n",
    "]\n",
    "\n",
    "X = df.drop(columns=[c for c in DROP_COLS if c in df.columns])\n",
    "y = df[TARGET]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e577256",
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOWS = {\n",
    "    \"W1\": ((\"2010-01-01\", \"2022-12-31\"), (\"2023-01-01\", \"2023-06-30\")),\n",
    "    \"W2\": ((\"2010-01-01\", \"2023-06-30\"), (\"2023-07-01\", \"2023-12-31\")),\n",
    "    \"W3\": ((\"2010-01-01\", \"2023-12-31\"), (\"2024-01-01\", \"2024-12-31\")),\n",
    "    \"W4\": ((\"2010-01-01\", \"2024-12-31\"), (\"2025-01-01\", \"2025-12-31\")), \n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385a7a47",
   "metadata": {},
   "source": [
    "#### Set Up trainning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35cc039",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324eb176",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ed32fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS = {\n",
    "    \"LightGBM\": LGBMClassifier(\n",
    "        objective=\"multiclass\",\n",
    "        class_weight=\"balanced\",\n",
    "        n_estimators=500,\n",
    "        learning_rate=0.05,\n",
    "        random_state=42\n",
    "    ),\n",
    "    \"XGBoost\": XGBClassifier(\n",
    "        objective=\"multi:softprob\",\n",
    "        eval_metric=\"mlogloss\",\n",
    "        n_estimators=500,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=6,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=42\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ab4d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for w_name, (train_rng, val_rng) in WINDOWS.items():\n",
    "    print(f\"\\n================ {w_name} ================\")\n",
    "\n",
    "    train_mask = (df['tanggal'] >= train_rng[0]) & (df['tanggal'] <= train_rng[1])\n",
    "    val_mask   = (df['tanggal'] >= val_rng[0])   & (df['tanggal'] <= val_rng[1])\n",
    "\n",
    "    X_train, X_val = X[train_mask], X[val_mask]\n",
    "    y_train, y_val = y_enc[train_mask], y_enc[val_mask]\n",
    "\n",
    "    print(f\"Train size: {X_train.shape}, Val size: {X_val.shape}\")\n",
    "\n",
    "    for model_name, model in MODELS.items():\n",
    "        print(f\"\\n--- {model_name} ---\")\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_val)\n",
    "\n",
    "        macro_f1 = f1_score(y_val, y_pred, average=\"macro\")\n",
    "        print(f\"Macro-F1: {macro_f1:.4f}\")\n",
    "\n",
    "        # Confusion Matrix\n",
    "        cm = confusion_matrix(y_val, y_pred)\n",
    "        print(\"Confusion Matrix:\")\n",
    "        print(cm)\n",
    "\n",
    "        # collapse check\n",
    "        if len(np.unique(y_pred)) < len(np.unique(y_val)):\n",
    "            print(\"⚠️ WARNING: model collapse ke kelas mayoritas\")\n",
    "\n",
    "        results.append({\n",
    "            \"window\": w_name,\n",
    "            \"model\": model_name,\n",
    "            \"macro_f1\": macro_f1\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2267d442",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "summary = (\n",
    "    results_df\n",
    "    .groupby(\"model\")[\"macro_f1\"]\n",
    "    .agg([\"mean\", \"std\"])\n",
    "    .sort_values(\"mean\", ascending=False)\n",
    ")\n",
    "\n",
    "print(\"\\n===== MODEL COMPARISON SUMMARY =====\")\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1636441f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rng, val_rng = WINDOWS[\"W3\"]\n",
    "\n",
    "train_mask = (df['tanggal'] >= train_rng[0]) & (df['tanggal'] <= train_rng[1])\n",
    "val_mask   = (df['tanggal'] >= val_rng[0])   & (df['tanggal'] <= val_rng[1])\n",
    "\n",
    "X_train, X_val = X[train_mask], X[val_mask]\n",
    "y_train, y_val = y_enc[train_mask], y_enc[val_mask]\n",
    "\n",
    "print(\"W3 Train:\", X_train.shape)\n",
    "print(\"W3 Val  :\", X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789fafa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        \"objective\": \"multiclass\",\n",
    "        \"class_weight\": \"balanced\",\n",
    "        \"n_estimators\": 500,\n",
    "\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.08),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 16, 64),\n",
    "        \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 30, 200),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n",
    "\n",
    "        \"feature_fraction\": trial.suggest_float(\"feature_fraction\", 0.6, 1.0),\n",
    "        \"bagging_fraction\": trial.suggest_float(\"bagging_fraction\", 0.6, 1.0),\n",
    "\n",
    "        \"random_state\": SEED,\n",
    "        \"n_jobs\": 1\n",
    "    }\n",
    "\n",
    "    model = LGBMClassifier(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_val)\n",
    "\n",
    "    # Macro-F1 (utama)\n",
    "    macro_f1 = f1_score(y_val, y_pred, average=\"macro\")\n",
    "\n",
    "    # Penalti collapse (jika prediksi < jumlah kelas)\n",
    "    n_pred_class = len(np.unique(y_pred))\n",
    "    n_true_class = len(np.unique(y_val))\n",
    "\n",
    "    if n_pred_class < n_true_class:\n",
    "        macro_f1 -= 0.05  # penalti ringan tapi tegas\n",
    "\n",
    "    return macro_f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f163bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7ec25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "N_TRIALS = 50\n",
    "pbar = tqdm(total=N_TRIALS, desc=\"Optuna Tuning (W3)\")\n",
    "\n",
    "def tqdm_callback(study, trial):\n",
    "    pbar.update(1)\n",
    "\n",
    "study = optuna.create_study(\n",
    "    direction=\"maximize\",\n",
    "    sampler=optuna.samplers.TPESampler(seed=SEED)\n",
    ")\n",
    "\n",
    "study.optimize(\n",
    "    objective,\n",
    "    n_trials=N_TRIALS,\n",
    "    callbacks=[tqdm_callback]  \n",
    ")\n",
    "\n",
    "pbar.close()  # <-- tutup progress bar\n",
    "\n",
    "print(\"Best Macro-F1 (W3):\", study.best_value)\n",
    "print(\"Best Params:\", study.best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb2dcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_train_mask = (\n",
    "    (df['tanggal'] >= \"2010-01-01\") &\n",
    "    (df['tanggal'] <= \"2024-12-31\")\n",
    ")\n",
    "\n",
    "X_final = X[final_train_mask]\n",
    "y_final = y_enc[final_train_mask]\n",
    "\n",
    "print(\"Final training size:\", X_final.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c64bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = study.best_params\n",
    "\n",
    "final_model = LGBMClassifier(\n",
    "    **best_params,\n",
    "    objective=\"multiclass\",\n",
    "    class_weight=\"balanced\",\n",
    "    n_estimators=500,\n",
    "    random_state=SEED,\n",
    "    n_jobs=1\n",
    ")\n",
    "\n",
    "final_model.fit(X_final, y_final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f28e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1_scores = {}\n",
    "\n",
    "for w_name, (train_rng, val_rng) in WINDOWS.items():\n",
    "\n",
    "    train_mask = (df['tanggal'] >= train_rng[0]) & (df['tanggal'] <= train_rng[1])\n",
    "    val_mask   = (df['tanggal'] >= val_rng[0])   & (df['tanggal'] <= val_rng[1])\n",
    "\n",
    "    X_train, X_val = X[train_mask], X[val_mask]\n",
    "    y_train, y_val = y_enc[train_mask], y_enc[val_mask]\n",
    "\n",
    "    model = LGBMClassifier(\n",
    "        **best_params,\n",
    "        objective=\"multiclass\",\n",
    "        class_weight=\"balanced\",\n",
    "        n_estimators=500,\n",
    "        random_state=SEED,\n",
    "        n_jobs=1\n",
    "    )\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_val)\n",
    "\n",
    "    f1 = f1_score(y_val, y_pred, average=\"macro\")\n",
    "    f1_scores[w_name] = f1\n",
    "\n",
    "    print(f\"{w_name} Macro-F1: {f1:.4f}\")\n",
    "\n",
    "print(\"\\nAverage Macro-F1:\", np.mean(list(f1_scores.values())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450e4efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(final_model, \"lgbm_ispu_model.pkl\")\n",
    "joblib.dump(le, \"label_encoder.pkl\")\n",
    "\n",
    "print(\"✅ Model dan LabelEncoder berhasil disimpan\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
