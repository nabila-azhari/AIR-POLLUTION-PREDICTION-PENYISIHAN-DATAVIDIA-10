{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datavidia ISPU Prediction - Fixed Version\n",
    "\n",
    "Notebook ini telah diperbaiki untuk mengatasi **Data Leakage** dan mengoptimalkan **Feature Engineering**. \n",
    "\n",
    "### Perbaikan Utama:\n",
    "1. **Anti-Leakage**: Menggunakan `shift(1)` pada semua fitur polutan dan cuaca sehingga model hanya memprediksi berdasarkan data masa lalu.\n",
    "2. **Efficient Rolling**: Menggunakan `groupby().transform()` untuk menghitung statistik bergerak (rolling mean) tanpa loop lambat.\n",
    "3. **Calendar Features**: Menambahkan fitur bulan dan hari dalam seminggu.\n",
    "4. **Balanced Weights**: Menggunakan `class_weight` untuk meningkatkan akurasi pada kategori minoritas (TIDAK SEHAT)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tanggal</th>\n",
       "      <th>periode_data</th>\n",
       "      <th>stasiun</th>\n",
       "      <th>pm_sepuluh</th>\n",
       "      <th>pm_duakomalima</th>\n",
       "      <th>sulfur_dioksida</th>\n",
       "      <th>karbon_monoksida</th>\n",
       "      <th>ozon</th>\n",
       "      <th>nitrogen_dioksida</th>\n",
       "      <th>max</th>\n",
       "      <th>...</th>\n",
       "      <th>cloud_cover_min (%)</th>\n",
       "      <th>wind_gusts_10m_mean (km/h)</th>\n",
       "      <th>wind_speed_10m_mean (km/h)</th>\n",
       "      <th>wind_gusts_10m_min (km/h)</th>\n",
       "      <th>wind_speed_10m_min (km/h)</th>\n",
       "      <th>surface_pressure_max (hPa)</th>\n",
       "      <th>surface_pressure_min (hPa)</th>\n",
       "      <th>lokasi</th>\n",
       "      <th>lokasi_clean</th>\n",
       "      <th>ndvi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>201001</td>\n",
       "      <td>DKI1 (Bunderan HI)</td>\n",
       "      <td>60.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>...</td>\n",
       "      <td>99.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>11.9</td>\n",
       "      <td>6.9</td>\n",
       "      <td>1009.3</td>\n",
       "      <td>1005.1</td>\n",
       "      <td>dki1_bundaranhi</td>\n",
       "      <td>DKI1</td>\n",
       "      <td>0.2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-01-02</td>\n",
       "      <td>201001</td>\n",
       "      <td>DKI1 (Bunderan HI)</td>\n",
       "      <td>32.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>...</td>\n",
       "      <td>91.0</td>\n",
       "      <td>16.5</td>\n",
       "      <td>7.7</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1009.9</td>\n",
       "      <td>1006.0</td>\n",
       "      <td>dki1_bundaranhi</td>\n",
       "      <td>DKI1</td>\n",
       "      <td>0.2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-01-03</td>\n",
       "      <td>201001</td>\n",
       "      <td>DKI1 (Bunderan HI)</td>\n",
       "      <td>27.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>...</td>\n",
       "      <td>81.0</td>\n",
       "      <td>18.4</td>\n",
       "      <td>9.4</td>\n",
       "      <td>11.9</td>\n",
       "      <td>6.5</td>\n",
       "      <td>1010.5</td>\n",
       "      <td>1006.5</td>\n",
       "      <td>dki1_bundaranhi</td>\n",
       "      <td>DKI1</td>\n",
       "      <td>0.2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>201001</td>\n",
       "      <td>DKI1 (Bunderan HI)</td>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>23.8</td>\n",
       "      <td>13.5</td>\n",
       "      <td>14.4</td>\n",
       "      <td>9.6</td>\n",
       "      <td>1009.1</td>\n",
       "      <td>1005.1</td>\n",
       "      <td>dki1_bundaranhi</td>\n",
       "      <td>DKI1</td>\n",
       "      <td>0.2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-01-05</td>\n",
       "      <td>201001</td>\n",
       "      <td>DKI1 (Bunderan HI)</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>...</td>\n",
       "      <td>99.0</td>\n",
       "      <td>21.6</td>\n",
       "      <td>11.1</td>\n",
       "      <td>10.4</td>\n",
       "      <td>7.8</td>\n",
       "      <td>1009.1</td>\n",
       "      <td>1006.0</td>\n",
       "      <td>dki1_bundaranhi</td>\n",
       "      <td>DKI1</td>\n",
       "      <td>0.2023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      tanggal  periode_data             stasiun  pm_sepuluh  pm_duakomalima  \\\n",
       "0  2010-01-01        201001  DKI1 (Bunderan HI)        60.0             NaN   \n",
       "1  2010-01-02        201001  DKI1 (Bunderan HI)        32.0             NaN   \n",
       "2  2010-01-03        201001  DKI1 (Bunderan HI)        27.0             NaN   \n",
       "3  2010-01-04        201001  DKI1 (Bunderan HI)        22.0             NaN   \n",
       "4  2010-01-05        201001  DKI1 (Bunderan HI)        25.0             NaN   \n",
       "\n",
       "   sulfur_dioksida  karbon_monoksida  ozon  nitrogen_dioksida   max  ...  \\\n",
       "0              4.0              73.0  27.0               14.0  73.0  ...   \n",
       "1              2.0              16.0  33.0                9.0  33.0  ...   \n",
       "2              2.0              19.0  20.0                9.0  27.0  ...   \n",
       "3              2.0              16.0  15.0                6.0  22.0  ...   \n",
       "4              2.0              17.0  15.0                8.0  25.0  ...   \n",
       "\n",
       "  cloud_cover_min (%) wind_gusts_10m_mean (km/h) wind_speed_10m_mean (km/h)  \\\n",
       "0                99.0                       21.0                       10.5   \n",
       "1                91.0                       16.5                        7.7   \n",
       "2                81.0                       18.4                        9.4   \n",
       "3                17.0                       23.8                       13.5   \n",
       "4                99.0                       21.6                       11.1   \n",
       "\n",
       "  wind_gusts_10m_min (km/h)  wind_speed_10m_min (km/h)  \\\n",
       "0                      11.9                        6.9   \n",
       "1                       9.0                        4.4   \n",
       "2                      11.9                        6.5   \n",
       "3                      14.4                        9.6   \n",
       "4                      10.4                        7.8   \n",
       "\n",
       "   surface_pressure_max (hPa)  surface_pressure_min (hPa)           lokasi  \\\n",
       "0                      1009.3                      1005.1  dki1_bundaranhi   \n",
       "1                      1009.9                      1006.0  dki1_bundaranhi   \n",
       "2                      1010.5                      1006.5  dki1_bundaranhi   \n",
       "3                      1009.1                      1005.1  dki1_bundaranhi   \n",
       "4                      1009.1                      1006.0  dki1_bundaranhi   \n",
       "\n",
       "   lokasi_clean    ndvi  \n",
       "0          DKI1  0.2023  \n",
       "1          DKI1  0.2023  \n",
       "2          DKI1  0.2023  \n",
       "3          DKI1  0.2023  \n",
       "4          DKI1  0.2023  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "\n",
    "NA_VALUES = [\"---\", \"--\", \"\", \" \", \"NA\", \"N/A\"]\n",
    "# =========================\n",
    "# FILE FINDER\n",
    "# =========================\n",
    "def find_file(name, start=Path.cwd()):\n",
    "    for ancestor in [start] + list(start.parents):\n",
    "        matches = list(ancestor.rglob(name))\n",
    "        if matches:\n",
    "            return matches[0]\n",
    "    return None\n",
    "\n",
    "\n",
    "def find_files(file_map):\n",
    "    found = {}\n",
    "    for key, filename in file_map.items():\n",
    "        path = find_file(filename)\n",
    "        if path:\n",
    "            found[key] = path\n",
    "        else:\n",
    "            print(f\"[WARNING] File not found: {filename}\")\n",
    "    return found\n",
    "\n",
    "eda_script_path = find_file(\"script_eda.py\")\n",
    "if eda_script_path is None:\n",
    "    raise FileNotFoundError(\"‚ùå script_eda.py tidak ditemukan di parent directory\")\n",
    "\n",
    "# tambahkan BASE PROJECT ke sys.path\n",
    "sys.path.append(str(eda_script_path.parent))\n",
    "\n",
    "# sekarang bisa import\n",
    "from script_eda import evaluate_dataset, extract_column_schema,find_internal_duplicate_columns,extract_single_schema,cek_value_data_column\n",
    "\n",
    "path = find_file(\"merged_cuaca_ndvi_ispu.csv\")\n",
    "\n",
    "if path is None:\n",
    "    raise FileNotFoundError(\"‚ùå File merged tidak ditemukan\")\n",
    "\n",
    "df = pd.read_csv(path, na_values=NA_VALUES)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Feature Engineering\n",
    "Kita akan membuat fitur lag dan rolling secara efisien."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî® Building features...\n",
      "Total features used: 53\n"
     ]
    }
   ],
   "source": [
    "def create_features(data):\n",
    "    data[\"tanggal\"] = pd.to_datetime(data[\"tanggal\"])\n",
    "    data = data.copy()\n",
    "    \n",
    "    # Fitur Kalender\n",
    "    data[\"month\"] = data[\"tanggal\"].dt.month\n",
    "    data[\"day_of_week\"] = data[\"tanggal\"].dt.dayofweek\n",
    "    data[\"is_weekend\"] = data[\"day_of_week\"].isin([5, 6]).astype(int)\n",
    "    \n",
    "    # List fitur dasar yang ingin diolah\n",
    "    POLLUTANTS = [\"pm_sepuluh\", \"sulfur_dioksida\", \"karbon_monoksida\", \"ozon\", \"nitrogen_dioksida\"]\n",
    "    WEATHER = [\n",
    "        \"temperature_2m_mean (¬∞C)\", \"relative_humidity_2m_mean (%)\",\n",
    "        \"precipitation_sum (mm)\", \"wind_speed_10m_mean (km/h)\", \"ndvi\"\n",
    "    ]\n",
    "    COLS_TO_SHIFT = POLLUTANTS + WEATHER\n",
    "    \n",
    "    for col in COLS_TO_SHIFT:\n",
    "        # Lag 1 (Kemarin), 2, 3\n",
    "        data[f\"{col}_lag_1\"] = data.groupby(\"lokasi_clean\")[col].shift(1)\n",
    "        data[f\"{col}_lag_2\"] = data.groupby(\"lokasi_clean\")[col].shift(2)\n",
    "        data[f\"{col}_lag_3\"] = data.groupby(\"lokasi_clean\")[col].shift(3)\n",
    "        \n",
    "        # Rolling Mean 7 hari (menggunakan data s/d kemarin)\n",
    "        data[f\"{col}_roll7\"] = (\n",
    "            data.groupby(\"lokasi_clean\")[col]\n",
    "            .transform(lambda x: x.shift(1).rolling(7, min_periods=3).mean())\n",
    "        )\n",
    "        \n",
    "        # Rolling Mean 3 hari\n",
    "        data[f\"{col}_roll3\"] = (\n",
    "            data.groupby(\"lokasi_clean\")[col]\n",
    "            .transform(lambda x: x.shift(1).rolling(3, min_periods=1).mean())\n",
    "        )\n",
    "        \n",
    "    return data\n",
    "\n",
    "print(\"üî® Building features...\")\n",
    "df_feat = create_features(df)\n",
    "\n",
    "# Pilih fitur final (Hanya fitur masa lalu + kalender)\n",
    "FEATURES = [c for c in df_feat.columns if \"_lag_\" in c or \"_roll\" in c or c in [\"month\", \"day_of_week\", \"is_weekend\"]]\n",
    "print(f\"Total features used: {len(FEATURES)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Model Training & Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 13845, Valid size: 1208\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004358 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8808\n",
      "[LightGBM] [Info] Number of data points in the train set: 13845, number of used features: 53\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score -2.265980\n",
      "[LightGBM] [Info] Start training from score -0.965046\n",
      "[LightGBM] [Info] Start training from score -0.662994\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Roaming\\Python\\Python312\\site-packages\\joblib\\externals\\loky\\backend\\context.py:136: UserWarning: Could not find the number of physical cores for the following reason:\n",
      "[WinError 2] The system cannot find the file specified\n",
      "Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.\n",
      "  warnings.warn(\n",
      "  File \"C:\\Users\\USER\\AppData\\Roaming\\Python\\Python312\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 257, in _count_physical_cores\n",
      "    cpu_info = subprocess.run(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Program Files\\Python312\\Lib\\subprocess.py\", line 548, in run\n",
      "    with Popen(*popenargs, **kwargs) as process:\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Program Files\\Python312\\Lib\\subprocess.py\", line 1026, in __init__\n",
      "    self._execute_child(args, executable, preexec_fn, close_fds,\n",
      "  File \"c:\\Program Files\\Python312\\Lib\\subprocess.py\", line 1538, in _execute_child\n",
      "    hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[320]\tvalid_0's multi_logloss: 0.73406\n",
      "\n",
      "--- VALIDATION REPORT ---\n",
      "Macro F1: 0.5076\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        BAIK       0.56      0.51      0.53       218\n",
      "      SEDANG       0.76      0.79      0.77       849\n",
      " TIDAK SEHAT       0.23      0.21      0.22       141\n",
      "\n",
      "    accuracy                           0.67      1208\n",
      "   macro avg       0.52      0.50      0.51      1208\n",
      "weighted avg       0.66      0.67      0.66      1208\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Mapping target ke angka\n",
    "df_feat[\"y\"] = df_feat[\"kategori\"].map(LABEL_MAP)\n",
    "\n",
    "# Split berdasarkan tanggal (Time Series Split)\n",
    "SPLIT_DATE = \"2024-12-31\"\n",
    "\n",
    "train_mask = (df_feat[\"tanggal\"] < SPLIT_DATE) & (df_feat[\"y\"].notna())\n",
    "valid_mask = (df_feat[\"tanggal\"] >= SPLIT_DATE) & (df_feat[\"y\"].notna())\n",
    "\n",
    "X_train, y_train = df_feat.loc[train_mask, FEATURES], df_feat.loc[train_mask, \"y\"]\n",
    "X_valid, y_valid = df_feat.loc[valid_mask, FEATURES], df_feat.loc[valid_mask, \"y\"]\n",
    "\n",
    "print(f\"Train size: {len(X_train)}, Valid size: {len(X_valid)}\")\n",
    "\n",
    "# Inisialisasi Model LightGBM\n",
    "model = lgb.LGBMClassifier(\n",
    "    objective=\"multiclass\",\n",
    "    num_class=3,\n",
    "    n_estimators=1000,\n",
    "    learning_rate=0.03,\n",
    "    class_weight={0: 1.0, 1: 0.8, 2: 4.5}, # Bobot tinggi untuk kategori TIDAK SEHAT\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_valid, y_valid)],\n",
    "    callbacks=[lgb.early_stopping(stopping_rounds=50)]\n",
    ")\n",
    "\n",
    "# Evaluasi\n",
    "y_pred = model.predict(X_valid)\n",
    "print(\"\\n--- VALIDATION REPORT ---\")\n",
    "print(f\"Macro F1: {f1_score(y_valid, y_pred, average='macro'):.4f}\")\n",
    "print(classification_report(y_valid, y_pred, target_names=LABEL_MAP.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Generation Submission\n",
    "Kita memprediksi kategori untuk data yang ada di `sample_submission.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-09-01_DKI1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-09-01_DKI2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-09-01_DKI3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-09-01_DKI4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-09-01_DKI5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                id  category\n",
       "0  2025-09-01_DKI1       NaN\n",
       "1  2025-09-01_DKI2       NaN\n",
       "2  2025-09-01_DKI3       NaN\n",
       "3  2025-09-01_DKI4       NaN\n",
       "4  2025-09-01_DKI5       NaN"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = find_file(\"sample_submission.csv\")\n",
    "\n",
    "if path is None:\n",
    "    raise FileNotFoundError(\"‚ùå File merged tidak ditemukan\")\n",
    "\n",
    "sub = pd.read_csv(path, na_values=NA_VALUES)\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ submission.csv berhasil dibuat!\n"
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# 4. GENERATE SUBMISSION (FORECASTING)\n",
    "# ===============================\n",
    "path = find_file(\"sample_submission.csv\")\n",
    "\n",
    "if path is None:\n",
    "    raise FileNotFoundError(\"‚ùå sample_submission.csv tidak ditemukan\")\n",
    "\n",
    "sub = pd.read_csv(path, na_values=NA_VALUES)\n",
    "\n",
    "# Ambil tanggal & lokasi dari id\n",
    "sub[\"tanggal\"] = pd.to_datetime(sub[\"id\"].str.split(\"_\").str[0])\n",
    "sub[\"lokasi_clean\"] = sub[\"id\"].str.split(\"_\").str[1]\n",
    "\n",
    "# Pastikan history terurut\n",
    "df_hist = df_feat.sort_values([\"lokasi_clean\", \"tanggal\"])\n",
    "\n",
    "rows = []\n",
    "\n",
    "for _, row in sub.iterrows():\n",
    "    loc = row[\"lokasi_clean\"]\n",
    "    tgl = row[\"tanggal\"]\n",
    "\n",
    "    # Ambil data historis sebelum tanggal prediksi\n",
    "    hist = df_hist[\n",
    "        (df_hist[\"lokasi_clean\"] == loc) &\n",
    "        (df_hist[\"tanggal\"] < tgl)\n",
    "    ].copy()\n",
    "\n",
    "    if len(hist) == 0:\n",
    "        pred_label = \"SEDANG\"  # fallback\n",
    "    else:\n",
    "        # Ambil baris terakhir sebagai basis fitur\n",
    "        last_row = hist.iloc[-1:].copy()\n",
    "\n",
    "        # Gunakan fitur yang sama seperti training\n",
    "        X_pred = last_row[FEATURES]\n",
    "\n",
    "        pred_num = model.predict(X_pred)[0]\n",
    "        pred_label = INV_LABEL_MAP[pred_num]\n",
    "\n",
    "    rows.append(pred_label)\n",
    "\n",
    "# Simpan submission\n",
    "sub[\"category\"] = rows\n",
    "sub[[\"id\", \"category\"]].to_csv(\"submission.csv\", index=False)\n",
    "\n",
    "print(\"‚úÖ submission.csv berhasil dibuat!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
